{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#description","title":"Description","text":"<p>CONCORD (COntrastive learNing for Cross-dOmain Reconciliation and Discovery) is a novel machine learning framework that leverages contrastive learning, masked autoencoders, and a unique batch construction strategy using data-aware sampling. CONCORD learns an encoding of cells that captures the cell state manifold, revealing both local and global structures. The resulting high-resolution atlas of cell states and trajectories is coherent across different domains, such as batches, technologies, and species. </p> <p>Full Documentation available at [insert documentation link].</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#1-clone-the-concord-repository-and-set-up-environment","title":"1. Clone the Concord repository and set up environment:","text":"<pre><code>git clone git@github.com:Gartner-Lab/Concord.git\n</code></pre> <p>It is recommended to use conda (https://conda.io/projects/conda/en/latest/user-guide/install/index.html) to create and set up virtual environment for Concord.</p>"},{"location":"#2-install-pytorch","title":"2. Install PyTorch:","text":"<p>You must install the correct version of PyTorch based on your system's CUDA setup. Please follow the instructions on the official PyTorch website to install the appropriate version of PyTorch for CUDA or CPU.</p> <p>Example (for CPU version): <pre><code>pip install torch torchvision torchaudio\n</code></pre></p>"},{"location":"#3-install-dependencies","title":"3. Install dependencies:","text":"<p>Navigate to the Concord directory and install the required dependencies:</p> <pre><code>cd path_to_Concord\npip install -r requirements.txt\n</code></pre>"},{"location":"#4-install-concord","title":"4. Install Concord:","text":"<p>Build and install Concord:</p> <pre><code>python setup.py sdist bdist_wheel\npip install dist/Concord-0.8.0-py3-none-any.whl\n</code></pre>"},{"location":"#5-optional-install-faiss-for-accelerated-knn-search-not-recommended-for-mac","title":"5. (Optional) Install FAISS for accelerated KNN search (not recommended for Mac):","text":"<p>Install FAISS for fast nearest-neighbor searches for large datasets. Note if you are using Mac, you should turn faiss off by specifying <code>cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, use_faiss=False, device=device)</code> when running Concord, unless you are certain faiss runs with no problem.</p> <ul> <li>FAISS with GPU:   <pre><code>pip install faiss_gpu\n</code></pre></li> <li>FAISS with CPU:   <pre><code>pip install faiss_cpu\n</code></pre></li> </ul>"},{"location":"#6-optional-install-optional-dependencies","title":"6. (Optional) Install optional dependencies:","text":"<p>Concord offers additional functionality through optional dependencies. You can install them via: <pre><code>pip install -r requirements_optional.txt\n</code></pre></p>"},{"location":"#7-optional-integration-with-viscello","title":"7. (Optional) Integration with VisCello:","text":"<p>Concord integrates with VisCello, a tool for interactive visualization. To explore results interactively, visit VisCello GitHub and refer to the full documentation for more information.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>The ipython notebook of this example can be found at Tutorial: PBMC3k dataset, single batch.</p>"},{"location":"#run-concord","title":"Run Concord","text":"<p>Concord seamlessly works with <code>anndata</code> objects. Here\u2019s an example run:</p> <pre><code>import Concord as ccd\nimport scanpy as sc\nimport torch\n\nadata = sc.datasets.pbmc3k_processed()\nadata = adata.raw.to_adata()  # Store raw counts in adata.X, by default Concord will run standard total count normalization and log transformation internally\n\n# Set device to cpu or to gpu (if your torch has been set up correctly to use GPU)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available)\nfeature_list = ccd.ul.select_features(adata, n_top_features=5000, flavor='seurat_v3')\n\n# Initialize Concord with an AnnData object, skip input_feature default to all features\ncur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, device=device) \n# If integrating data across batch, simply add the domain_key argument\n# cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='batch', device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key='Concord')\n</code></pre>"},{"location":"#visualize-results","title":"Visualize Results:","text":"<p>We recommend using UMAP to visualize Concord embeddings:</p> <pre><code>ccd.ul.run_umap(adata, source_key='Concord', umap_key='Concord_UMAP', n_components=2, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the UMAP embeddings\ncolor_by = ['n_genes', 'louvain'] # Choose which variables you want to visualize\nccd.pl.plot_embedding(\n    adata, basis='Concord_UMAP', color_by=color_by, figsize=(10, 5), dpi=600, ncols=2, font_size=6, point_size=10, legend_loc='on data',\n    save_path='Concord_UMAP.png'\n)\n</code></pre>"},{"location":"#3d-visualization","title":"3D Visualization:","text":"<p>For complex structures, 3D UMAP may provide better insights:</p> <pre><code>ccd.ul.run_umap(adata, source_key='Concord', umap_key='Concord_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'louvain'\nccd.pl.plot_embedding_3d(\n    adata, basis='Concord_UMAP_3D', color_by=col,\n    save_path='Concord_UMAP_3D.html',\n    point_size=10, opacity=0.8, width=1500, height=1000\n)\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>Concord is currently available on BioRxiv. Please cite the preprint here: [Insert citation link].</p>"},{"location":"LICENSE/","title":"License","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public: \nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"about/","title":"Citation &amp; Feedback","text":""},{"location":"about/#cite-concord","title":"Cite CONCORD","text":"<p>If you find CONCORD helpful for your research, please consider citing our work:</p> <p>\ud83d\udcc4 CONCORD Paper</p>"},{"location":"about/#feedback-troubleshooting","title":"Feedback &amp; Troubleshooting","text":"<p>We appreciate any feedback on CONCORD! You can reach out via email or GitHub:</p> <p>\ud83d\udce7 General inquiries &amp; feedback: qin.zhu@ucsf.edu \ud83d\udc1b Report issues on GitHub: Gartner-Lab/Concord \ud83d\udce2 Collaborations: zev.gartner@ucsf.edu </p> <p>Feel free to get in touch! \ud83d\ude80</p>"},{"location":"advanced/","title":"Advanced usage","text":""},{"location":"api/","title":"CONCORD","text":""},{"location":"api/#Concord.Concord","title":"<code>Concord.Concord</code>","text":"<p>A contrastive learning framework for single-cell data analysis.</p> <p>CONCORD performs dimensionality reduction, denoising, and batch correction  in an unsupervised manner while preserving local and global topological structures.</p> <p>Attributes:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>Input AnnData object.</p> <code>save_dir</code> <code>Path</code> <p>Directory to save outputs and logs.</p> <code>config</code> <code>Config</code> <p>Configuration object storing hyperparameters.</p> <code>model</code> <code>ConcordModel</code> <p>The main contrastive learning model.</p> <code>trainer</code> <code>Trainer</code> <p>Handles model training.</p> <code>loader</code> <code>DataLoaderManager or ChunkLoader</code> <p>Data loading utilities.</p>"},{"location":"api/#Concord.Concord.__init__","title":"<code>__init__(adata, save_dir='save/', inplace=True, use_wandb=False, verbose=False, **kwargs)</code>","text":"<p>Initializes the Concord framework.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Input single-cell data in AnnData format.</p> required <code>save_dir</code> <code>str</code> <p>Directory to save model outputs. Defaults to 'save/'.</p> <code>'save/'</code> <code>inplace</code> <code>bool</code> <p>If True, modifies <code>adata</code> in place. Defaults to True.</p> <code>True</code> <code>use_wandb</code> <code>bool</code> <p>Whether to enable Weights &amp; Biases logging. Defaults to False.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Enable verbose logging. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <p>Additional configuration parameters.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>inplace</code> is set to True on a backed AnnData object.</p>"},{"location":"api/#Concord.Concord.get_default_params","title":"<code>get_default_params()</code>","text":"<p>Returns the default hyperparameters used in CONCORD.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing default configuration values.</p>"},{"location":"api/#Concord.Concord.setup_config","title":"<code>setup_config(**kwargs)</code>","text":"<p>Sets up the configuration for training.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Key-value pairs to override default parameters.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid parameter is provided.</p>"},{"location":"api/#Concord.Concord.init_model","title":"<code>init_model()</code>","text":"<p>Initializes the CONCORD model and loads a pre-trained model if specified.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified pre-trained model file is missing.</p>"},{"location":"api/#Concord.Concord.init_trainer","title":"<code>init_trainer()</code>","text":"<p>Initializes the model trainer, setting up loss functions, optimizer, and learning rate scheduler.</p>"},{"location":"api/#Concord.Concord.init_dataloader","title":"<code>init_dataloader(input_layer_key='X_log1p', preprocess=True, train_frac=1.0, use_sampler=True)</code>","text":"<p>Initializes the data loader for training and evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>input_layer_key</code> <code>str</code> <p>Key in <code>adata.layers</code> to use as input. Defaults to 'X_log1p'.</p> <code>'X_log1p'</code> <code>preprocess</code> <code>bool</code> <p>Whether to apply preprocessing. Defaults to True.</p> <code>True</code> <code>train_frac</code> <code>float</code> <p>Fraction of data to use for training. Defaults to 1.0.</p> <code>1.0</code> <code>use_sampler</code> <code>bool</code> <p>Whether to use the probabilistic sampler. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>train_frac &lt; 1.0</code> and contrastive loss mode is 'nn'.</p>"},{"location":"api/#Concord.Concord.train","title":"<code>train(save_model=True, patience=2)</code>","text":"<p>Trains the model on the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>save_model</code> <code>bool</code> <p>Whether to save the trained model. Defaults to True.</p> <code>True</code> <code>patience</code> <code>int</code> <p>Number of epochs to wait for improvement before early stopping. Defaults to 2.</p> <code>2</code>"},{"location":"api/#Concord.Concord.predict","title":"<code>predict(loader, sort_by_indices=False, return_decoded=False, decoder_domain=None, return_latent=False, return_class=True, return_class_prob=True)</code>","text":"<p>Runs inference on a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>loader</code> <code>DataLoader or list</code> <p>Data loader or chunked loader for batch processing.</p> required <code>sort_by_indices</code> <code>bool</code> <p>Whether to return results in original cell order. Defaults to False.</p> <code>False</code> <code>return_decoded</code> <code>bool</code> <p>Whether to return decoded gene expression. Defaults to False.</p> <code>False</code> <code>decoder_domain</code> <code>str</code> <p>Specifies a domain for decoding. Defaults to None.</p> <code>None</code> <code>return_latent</code> <code>bool</code> <p>Whether to return latent variables. Defaults to False.</p> <code>False</code> <code>return_class</code> <code>bool</code> <p>Whether to return predicted class labels. Defaults to True.</p> <code>True</code> <code>return_class_prob</code> <code>bool</code> <p>Whether to return class probabilities. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>Encoded embeddings, decoded matrix (if requested), class predictions, class probabilities, true labels, and latent variables.</p>"},{"location":"api/#Concord.Concord.encode_adata","title":"<code>encode_adata(input_layer_key='X_log1p', output_key='Concord', preprocess=True, return_decoded=False, decoder_domain=None, return_latent=False, return_class=True, return_class_prob=True, save_model=True)</code>","text":"<p>Encodes an AnnData object using the CONCORD model.</p> <p>Parameters:</p> Name Type Description Default <code>input_layer_key</code> <code>str</code> <p>Input layer key. Defaults to 'X_log1p'.</p> <code>'X_log1p'</code> <code>output_key</code> <code>str</code> <p>Output key for storing results in AnnData. Defaults to 'Concord'.</p> <code>'Concord'</code> <code>preprocess</code> <code>bool</code> <p>Whether to apply preprocessing. Defaults to True.</p> <code>True</code> <code>return_decoded</code> <code>bool</code> <p>Whether to return decoded gene expression. Defaults to False.</p> <code>False</code> <code>decoder_domain</code> <code>str</code> <p>Specifies domain for decoding. Defaults to None.</p> <code>None</code> <code>return_latent</code> <code>bool</code> <p>Whether to return latent variables. Defaults to False.</p> <code>False</code> <code>return_class</code> <code>bool</code> <p>Whether to return predicted class labels. Defaults to True.</p> <code>True</code> <code>return_class_prob</code> <code>bool</code> <p>Whether to return class probabilities. Defaults to True.</p> <code>True</code> <code>save_model</code> <code>bool</code> <p>Whether to save the model after training. Defaults to True.</p> <code>True</code>"},{"location":"api/#Concord.Concord.get_domain_embeddings","title":"<code>get_domain_embeddings()</code>","text":"<p>Retrieves domain embeddings from the trained model.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: A dataframe containing domain embeddings.</p>"},{"location":"api/#Concord.Concord.get_covariate_embeddings","title":"<code>get_covariate_embeddings()</code>","text":"<p>Retrieves covariate embeddings from the trained model.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary of DataFrames, each containing embeddings for a covariate.</p>"},{"location":"api/#Concord.Concord.save_model","title":"<code>save_model(model, save_path)</code>","text":"<p>Saves the trained model to a file.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The trained model.</p> required <code>save_path</code> <code>str or Path</code> <p>Path to save the model file.</p> required <p>Returns:</p> Type Description <p>None</p>"},{"location":"api/#plotting","title":"Plotting","text":""},{"location":"api/#Concord.plotting.pl_batch.visualize_batch_composition","title":"<code>Concord.plotting.pl_batch.visualize_batch_composition(dataloader, adata, batch_indices=None, data_structure=None, attribute='class', attribute_key=None, figsize=(12, 5), save_path=None)</code>","text":"<p>Visualize the composition of specified batches in terms of class or domain.</p> <p>Parameters: - chunk_loader: Chunk loader object containing the dataloaders. - data_structure: Structure of the data in the dataloader. - attribute: 'class' or 'domain' to specify the attribute to visualize. - attribute_key: Key to access the attribute names in adata. - save_path: Optional path to save the plot. - max_batches: Maximum number of batches to visualize.</p>"},{"location":"framework/","title":"The CONCORD Framework","text":""},{"location":"framework/#what-does-concord-do","title":"What Does CONCORD Do?","text":"<p>CONCORD tackles three central challenges in single-cell data analysis: dimensionality reduction, denoising, and data integration. Operating in a one-shot, fully unsupervised manner, it produces denoised cell embeddings that capture the essential topological and geometric features of the underlying biological manifold\u2014revealing fine-grained local details while preserving a coherent global structure.</p> <p></p> <p>Beyond its core functionality, CONCORD supports additional tasks such as cell type classification (via label transfer), doublet calling, data projection, and annotation-guided latent representation. It also includes two key modules:</p> <ul> <li> <p>Simulation Module: Generates various topologies\u2014clusters, trajectories, trees, and loops\u2014commonly observed in single-cell data, with customizable batch effects.</p> </li> <li> <p>Benchmarking Module: Provides comprehensive evaluation statistics, including topological and geometric assessments.</p> </li> </ul> <p>Moreover, CONCORD offers tools for creating publication-quality visualizations.</p>"},{"location":"framework/#what-makes-concord-powerful","title":"What makes CONCORD powerful?","text":"<p>CONCORD introduces a novel contrastive learning framework designed to denoise and reveal the intricate structure of the cellular state manifold across one or multiple datasets. Its core innovation lies in its probabilistic sampling framework, which seamlessly integrates two strategies:</p> <ul> <li>Neighborhood-Aware Sampling:   Adapted from the kNN sampler, this approach enables the model to explore local regions in depth while maintaining a global perspective. Instead of uniformly sampling \u201ceasy negatives\u201d from the overall distribution, CONCORD selectively draws \u201chard negatives\u201d from nearby cells, capturing subtle distinctions among closely related cell states.</li> </ul> <p></p> <ul> <li>Dataset-Aware Sampling:   This strategy addresses data integration by contrasting cells within a single dataset at a time, rather than combining cells from multiple datasets in one mini-batch. By leveraging only the sampler and the contrastive objective, CONCORD effectively disentangles biological variation from dataset-specific artifacts\u2014without the need for explicit batch-effect assumptions or adversarial training.</li> </ul> <p></p> <p>Together, these sampling strategies demonstrate that substantial improvements in contrastive learning can be achieved through principled sampling and training alone\u2014without resorting to complex model architectures or additional loss terms. Unifying both approaches into a single probabilistic framework, CONCORD enhances embedding resolution while mitigating batch effects.</p> <p></p>"},{"location":"framework/#model-architecture","title":"Model Architecture","text":"<p>The current CONCORD model employs a minimalist design\u2014a simple two-layer encoder with optional decoder and classifier heads. Notably, the probabilistic sampler is versatile and can be integrated with alternative architectures as well.</p> <p></p>"},{"location":"galleries/cbce_show/","title":"3D CONCORD UMAP of C. elegans and C. briggsae Embryogenesis","text":"<ul> <li>Data from Large, Christopher RL, et al. \"Lineage-resolved analysis of embryonic gene expression evolution in C. elegans and C. briggsae.\" bioRxiv (2024): 2024-02, visualized with 3D UMAP with CONCORD latent.</li> </ul> Embryo TimeGerm layer/tissueCell TypeLineageSpecies"},{"location":"galleries/huycke_show/","title":"3D CONCORD UMAP of Intestine Development Atlas","text":"<ul> <li>Data from Huycke, Tyler R., et al. \"Patterning and folding of intestinal villi by active mesenchymal dewetting.\" Cell 187.12 (2024): 3072-3089, visualized with 3D UMAP with CONCORD latent.</li> </ul> Cell cycleBroad cell typeZonationDevelopmental stageBatch"},{"location":"notebooks/concord_Huycke/","title":"Intestine development by Huycke et al.","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import Concord as ccd\nimport scanpy as sc\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata_path = \"../data/intestine_dev/intestine_adata.h5ad\"\nadata = sc.read(\n    data_path\n)\n\nadata.layers[\"counts\"] = adata.X.copy()\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nccd.ul.score_cell_cycle(adata, organism='Mm')\n</pre> import Concord as ccd import scanpy as sc import torch import warnings warnings.filterwarnings('ignore')  data_path = \"../data/intestine_dev/intestine_adata.h5ad\" adata = sc.read(     data_path )  adata.layers[\"counts\"] = adata.X.copy() sc.pp.normalize_total(adata) sc.pp.log1p(adata) ccd.ul.score_cell_cycle(adata, organism='Mm') <pre>Concord - INFO - Processed 43 human genes to mouse orthologs.\nConcord - INFO - Processed 54 human genes to mouse orthologs.\n</pre> In\u00a0[3]: Copied! <pre>import time\nfrom pathlib import Path\nproj_name = \"concord_Huycke_intestine\"\nsave_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\"\nsave_dir = Path(save_dir)\nsave_dir.mkdir(parents=True, exist_ok=True)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d')}\"\nseed = 0\n</pre> import time from pathlib import Path proj_name = \"concord_Huycke_intestine\" save_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\" save_dir = Path(save_dir) save_dir.mkdir(parents=True, exist_ok=True) device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') file_suffix = f\"{proj_name}_{time.strftime('%b%d')}\" seed = 0 <p>Dropout is one of the major patterns in single cell data. Even nearby cells can have significant proportion of non-overlapping non-zero genes, which could be due to technical drop-out or real biology (genes stochastically turned on or off). Concord 'augments' the data by introducing dropout to each of the cell, and use contrastive learning to 'self-supervise' the model to learn the cell identity despite the presence of dropout. The augment dropout probability can be custom-defined, or be estimated based on the average dropout rate in the current data. Here we provide a detailed example how this is calculated:</p> In\u00a0[103]: Copied! <pre># Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available)\noutput_key = 'Concord'\nfeature_list = ccd.ul.select_features(adata, n_top_features=10000, flavor='seurat_v3')\n# Determine augmentation mask probabilities based on estimated dropout rate from knn neighbors\ndropout_est = ccd.ul.estimate_aug_mask_prob(adata, input_feature = feature_list, n_samples = adata.n_obs, return_mean=False, plotting=True)\n</pre> # Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available) output_key = 'Concord' feature_list = ccd.ul.select_features(adata, n_top_features=10000, flavor='seurat_v3') # Determine augmentation mask probabilities based on estimated dropout rate from knn neighbors dropout_est = ccd.ul.estimate_aug_mask_prob(adata, input_feature = feature_list, n_samples = adata.n_obs, return_mean=False, plotting=True)  <pre>Concord.utils.feature_selector - INFO - Selecting highly variable features with flavor seurat_v3...\n</pre> In\u00a0[86]: Copied! <pre># Save for concord run and visualization\nadata.obs['dropout_est'] = dropout_est\naug_prob = dropout_est.mean()\n</pre> # Save for concord run and visualization adata.obs['dropout_est'] = dropout_est aug_prob = dropout_est.mean() <p>Here's one specific example showing the gene set difference between a cell and its 3 nearest neighbors.</p> In\u00a0[73]: Copied! <pre>from Concord.model.knn import Neighborhood\nimport numpy as np\nemb = adata.obsm['X_pca']\nneighborhood = Neighborhood(emb=emb, k=3)\ncore_samples = np.array([9000])\nX = adata.X.toarray()\navg_distances = neighborhood.average_knn_distance(core_samples, X, k=3, distance_metric='drop_diff')\nprint(avg_distances)\nindices = neighborhood.get_knn_indices(core_samples, k=3, include_self=False)\nprint(adata.obs['cell_type'].iloc[core_samples])\nprint(adata.obs['cell_type'].iloc[indices.flatten()])\n</pre> from Concord.model.knn import Neighborhood import numpy as np emb = adata.obsm['X_pca'] neighborhood = Neighborhood(emb=emb, k=3) core_samples = np.array([9000]) X = adata.X.toarray() avg_distances = neighborhood.average_knn_distance(core_samples, X, k=3, distance_metric='drop_diff') print(avg_distances) indices = neighborhood.get_knn_indices(core_samples, k=3, include_self=False) print(adata.obs['cell_type'].iloc[core_samples]) print(adata.obs['cell_type'].iloc[indices.flatten()])  <pre>Concord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\n</pre> Out[73]: <pre>array([0.4884242])</pre> In\u00a0[81]: Copied! <pre>import seaborn as sns\nimport sys\nsys.setrecursionlimit(10000)\nmtx = adata.X.toarray()\ncore_nonzero = (mtx[core_samples] &gt; 0)  # Boolean array for non-zero genes in core cells\nneighbor_nonzero = (mtx[indices] &gt; 0)   # Boolean array for non-zero genes in neighbors\ncbn_indices = np.concatenate([core_samples, indices.flatten()])\nsns.clustermap(mtx[cbn_indices], row_cluster=False, col_cluster=True, cmap='viridis', figsize=(7, 3))\n</pre> import seaborn as sns import sys sys.setrecursionlimit(10000) mtx = adata.X.toarray() core_nonzero = (mtx[core_samples] &gt; 0)  # Boolean array for non-zero genes in core cells neighbor_nonzero = (mtx[indices] &gt; 0)   # Boolean array for non-zero genes in neighbors cbn_indices = np.concatenate([core_samples, indices.flatten()]) sns.clustermap(mtx[cbn_indices], row_cluster=False, col_cluster=True, cmap='viridis', figsize=(7, 3)) Out[81]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f22879c9c40&gt;</pre> In\u00a0[91]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='LaneID', \n                      latent_dim=32,\n                      augmentation_mask_prob = aug_prob, \n                      clr_temperature = .3, # Check out advanced usage to learn what this parameter controls\n                      min_p_intra_domain=1.0, \n                      seed=seed, \n                      inplace=False, \n                      verbose=True, \n                      device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a filem, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\nadata.obsm = cur_ccd.adata.obsm # If not inplace\n</pre> cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='LaneID',                        latent_dim=32,                       augmentation_mask_prob = aug_prob,                        clr_temperature = .3, # Check out advanced usage to learn what this parameter controls                       min_p_intra_domain=1.0,                        seed=seed,                        inplace=False,                        verbose=True,                        device=device)   # Encode data, saving the latent embedding in adata.obsm['Concord'] cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a filem, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") adata.obsm = cur_ccd.adata.obsm # If not inplace <pre>Concord - INFO - Setting sampler_knn to 1309 to be 1/50 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - INFO - Column 'LaneID' is already of type: category\nConcord - INFO - Unused levels dropped for column 'LaneID'.\nConcord - INFO - Encoder input dim: 10000\nConcord - INFO - Decoder input dim: 40\nConcord - INFO - Model loaded to device: cuda:0\nConcord - INFO - Total number of parameters: 2590128\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (10000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 65468 samples. Data structure: ['input', 'domain', 'idx']\nConcord.model.dataloader - INFO - Using existing embedding 'X_pca' from adata.obsm\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss IVF index. nprobe=10\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.dataloader - INFO - Number of unique_domains: 6\nConcord.model.dataloader - INFO - Calculating each domain's coverage of the global manifold using X_pca.\nConcord.model.dataloader - INFO - Converting coverage to p_intra_domain...\nConcord.model.dataloader - INFO - Final p_intra_domain values: L1: 1.00, L2: 1.00, R: 1.00, Live_1: 1.00, Live_2: 1.00, Rare: 1.00\nConcord - INFO - Starting epoch 1/5\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>Epoch 0 Training: 1020it [00:32, 31.28it/s, loss=3.05]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 3.33, MSE: 0.09, CLASS: 0.00, CONTRAST: 3.24, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 2/5\nConcord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1020/1020 [00:30&lt;00:00, 33.47it/s, loss=3.06]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 2.99, MSE: 0.06, CLASS: 0.00, CONTRAST: 2.93, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 3/5\nConcord - INFO - Processing chunk 1/1 for epoch 3\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1020/1020 [00:27&lt;00:00, 36.61it/s, loss=2.94]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 2.94, MSE: 0.06, CLASS: 0.00, CONTRAST: 2.88, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 4/5\nConcord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1020/1020 [00:28&lt;00:00, 36.01it/s, loss=3.09]</pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 2.91, MSE: 0.06, CLASS: 0.00, CONTRAST: 2.85, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 5/5\nConcord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1020/1020 [00:29&lt;00:00, 34.81it/s, loss=3.05]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 2.89, MSE: 0.06, CLASS: 0.00, CONTRAST: 2.83, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Model saved to save/final_model.pth\nConcord - INFO - Final model saved at: save/final_model.pth; Configuration saved at: save/config.json.\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (10000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 65468 samples. Data structure: ['input', 'domain', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[100]: Copied! <pre>#ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['MouseAge_combined', 'seg_classify', 'phase', 'batch', 'cell_type', \"mes_subtype\", \"dropout_est\"]\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(13,12), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> #ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['MouseAge_combined', 'seg_classify', 'phase', 'batch', 'cell_type', \"mes_subtype\", \"dropout_est\"] ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(13,12), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <p>It is best to use 3D UMAP rather than 2D to visualize Concord latent, because 2D may not be enough to 'unpack' the complex structures learned by Concord, thus tends to break trajectories.</p> In\u00a0[93]: Copied! <pre>import plotly.io as pio\npio.renderers.default = 'notebook'\nccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\n#show_cols = ['MouseAge_combined', 'seg_classify', 'phase', 'batch', 'cell_type', \"mes_subtype\"]\ncol = 'cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata, basis=show_basis, color_by=col,\n        save_path=save_dir / f'{show_basis}_{file_suffix}.html',\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> import plotly.io as pio pio.renderers.default = 'notebook' ccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings #show_cols = ['MouseAge_combined', 'seg_classify', 'phase', 'batch', 'cell_type', \"mes_subtype\"] col = 'cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata, basis=show_basis, color_by=col,         save_path=save_dir / f'{show_basis}_{file_suffix}.html',         point_size=1, opacity=0.8, width=1500, height=1000     ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Concord_UMAP_3D']\nConcord - INFO - 3D plot saved to ../save/dev_concord_Huycke_intestine-Sep29/Concord_UMAP_3D_concord_Huycke_intestine_Sep29.html\n</pre> <p>We can just visualize the Mesenchmal cell (Pdgfra hi/lo) subset, note the loop of cell cycle and the differentiation from Pdgfra-lo to Pdgfra-hi cells.</p> In\u00a0[97]: Copied! <pre>col = 'mes_subtype'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata, basis=show_basis, color_by=col,\n        save_path=save_dir / f'{show_basis}_{file_suffix}.html',\n        point_size=1, opacity=0.8, width=1500, height=800\n    )\n</pre> col = 'mes_subtype' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata, basis=show_basis, color_by=col,         save_path=save_dir / f'{show_basis}_{file_suffix}.html',         point_size=1, opacity=0.8, width=1500, height=800     ) <pre>Concord - INFO - 3D plot saved to ../save/dev_concord_Huycke_intestine-Sep29/Concord_UMAP_3D_concord_Huycke_intestine_Sep29.html\n</pre> In\u00a0[101]: Copied! <pre>obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\"\nccd.ul.save_obsm_to_hdf5(adata, obsm_filename)\nadata.write_h5ad(\"../data/intestine_dev/intestine_adata_concord_{file_suffix}.h5ad\")\n</pre> obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\" ccd.ul.save_obsm_to_hdf5(adata, obsm_filename) adata.write_h5ad(\"../data/intestine_dev/intestine_adata_concord_{file_suffix}.h5ad\") <p>You can optionally convert the result to VisCello (https://github.com/kimpenn/VisCello) for interactive exploration.</p> In\u00a0[\u00a0]: Copied! <pre>ccd.ul.anndata_to_viscello(adata, save_dir / f\"cello_{proj_name}_{file_suffix}\", project_name = proj_name, organism='mmu')\n</pre> ccd.ul.anndata_to_viscello(adata, save_dir / f\"cello_{proj_name}_{file_suffix}\", project_name = proj_name, organism='mmu')"},{"location":"notebooks/concord_Huycke/#basic-setup","title":"Basic setup\u00b6","text":""},{"location":"notebooks/concord_Huycke/#define-feature-input-and-estimate-dropout-rate-in-data","title":"Define feature input and estimate dropout rate in data\u00b6","text":""},{"location":"notebooks/concord_Huycke/#run-concord","title":"Run Concord\u00b6","text":""},{"location":"notebooks/concord_Huycke/#visualize-concord-latent-with-umap","title":"Visualize Concord latent with UMAP\u00b6","text":""},{"location":"notebooks/concord_Huycke/#2d-umap","title":"2D UMAP\u00b6","text":""},{"location":"notebooks/concord_Huycke/#3d-umap","title":"3D UMAP\u00b6","text":""},{"location":"notebooks/concord_Huycke/#save-the-result","title":"Save the result\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/","title":"Mouse organogenesis (100k subset)","text":"<p>Dataset from The single-cell transcriptional landscape of mammalian organogenesis by Cao et al., Nature (2019). This notebook runs on the 100k data subset from https://oncoscape.v3.sttrcancer.org/atlas.gs.washington.edu.mouse.rna/downloads.</p> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[24]: Copied! <pre>import Concord as ccd\nimport scanpy as sc\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata_path = \"../data/mouse_organogenesis/adata_sampled_100k.h5ad\"\nadata = sc.read(\n    data_path\n)\nimport pandas as pd\n# Make sure that the gene names are unique\ngene_names = adata.var['gene_short_name']\ngene_names_unique = pd.Series(pd.Index(gene_names)).astype(str)\ngene_names_unique = pd.Index(gene_names_unique.where(~gene_names_unique.duplicated(), gene_names_unique + \"_\" + gene_names_unique.groupby(gene_names_unique).cumcount().astype(str)))\nadata.var_names = gene_names_unique\nadata.var.index.name = None\nadata.layers[\"counts\"] = adata.X.copy()\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nadata.var\nccd.ul.score_cell_cycle(adata, organism='Mm')\n</pre> import Concord as ccd import scanpy as sc import torch import warnings warnings.filterwarnings('ignore')  data_path = \"../data/mouse_organogenesis/adata_sampled_100k.h5ad\" adata = sc.read(     data_path ) import pandas as pd # Make sure that the gene names are unique gene_names = adata.var['gene_short_name'] gene_names_unique = pd.Series(pd.Index(gene_names)).astype(str) gene_names_unique = pd.Index(gene_names_unique.where(~gene_names_unique.duplicated(), gene_names_unique + \"_\" + gene_names_unique.groupby(gene_names_unique).cumcount().astype(str))) adata.var_names = gene_names_unique adata.var.index.name = None adata.layers[\"counts\"] = adata.X.copy() sc.pp.normalize_total(adata) sc.pp.log1p(adata) adata.var ccd.ul.score_cell_cycle(adata, organism='Mm') <pre>Concord - INFO - Processed 43 human genes to mouse orthologs.\nConcord - INFO - Processed 54 human genes to mouse orthologs.\n</pre> In\u00a0[65]: Copied! <pre># Check GPU availability and cuda version\nimport os\nos.system('nvidia-smi')\n</pre> # Check GPU availability and cuda version import os os.system('nvidia-smi') <pre>Sun Sep 29 16:05:47 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce GTX 1080        Off | 00000000:02:00.0 Off |                  N/A |\n| 43%   57C    P2              42W / 180W |   7894MiB /  8192MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce GTX 1080        Off | 00000000:03:00.0 Off |                  N/A |\n| 28%   19C    P8               6W / 180W |      2MiB /  8192MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   2  NVIDIA GeForce GTX 1080        Off | 00000000:81:00.0 Off |                  N/A |\n| 28%   21C    P8               7W / 180W |      2MiB /  8192MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   3  NVIDIA GeForce GTX 1080        Off | 00000000:82:00.0 Off |                  N/A |\n| 27%   18C    P8               6W / 180W |      2MiB /  8192MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A   1480407      C   ...qin/.conda/envs/cellpath/bin/python      670MiB |\n|    0   N/A  N/A   3654886      C   python                                     7222MiB |\n+---------------------------------------------------------------------------------------+\n</pre> Out[65]: <pre>0</pre> In\u00a0[25]: Copied! <pre>import time\nfrom pathlib import Path\nproj_name = \"concord_mouse_organogenesis_100k\"\nsave_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\"\nsave_dir = Path(save_dir)\nsave_dir.mkdir(parents=True, exist_ok=True)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d')}\"\nseed = 0\n</pre> import time from pathlib import Path proj_name = \"concord_mouse_organogenesis_100k\" save_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\" save_dir = Path(save_dir) save_dir.mkdir(parents=True, exist_ok=True) device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') file_suffix = f\"{proj_name}_{time.strftime('%b%d')}\" seed = 0 In\u00a0[62]: Copied! <pre>col = 'Main_cell_type'\nshow_basis = f'Original_main_umap'\nccd.ul.ensure_categorical(adata, col)\nccd.pl.plot_embedding_3d(\n        adata, basis=show_basis, color_by=col,\n        save_path=save_dir / f'{show_basis}_{file_suffix}.html',\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> col = 'Main_cell_type' show_basis = f'Original_main_umap' ccd.ul.ensure_categorical(adata, col) ccd.pl.plot_embedding_3d(         adata, basis=show_basis, color_by=col,         save_path=save_dir / f'{show_basis}_{file_suffix}.html',         point_size=1, opacity=0.8, width=1500, height=1000     ) <pre>Concord - INFO - Column 'Main_cell_type' is already of type: category\nConcord - INFO - Unused levels dropped for column 'Main_cell_type'.\n</pre> <pre>Concord - INFO - 3D plot saved to ../save/dev_concord_mouse_organogenesis_100k-Sep29/Original_main_umap_concord_mouse_organogenesis_100k_Sep29.html\n</pre> <p>Dropout is one of the major patterns in single cell data. Even nearby cells can have significant proportion of non-overlapping non-zero genes, which could be due to technical drop-out or real biology (genes stochastically turned on or off). Concord 'augments' the data by introducing dropout to each of the cell, and use contrastive learning to 'self-supervise' the model to learn the cell identity despite the presence of dropout. The augment dropout probability can be custom-defined, or be estimated based on the average dropout rate in the current data. Here we provide a detailed example how this is calculated:</p> In\u00a0[26]: Copied! <pre># Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available)\noutput_key = 'Concord'\nfeature_list = ccd.ul.select_features(adata, n_top_features=10000, flavor='seurat_v3')\n# Determine augmentation mask probabilities based on estimated dropout rate from knn neighbors\ndropout_est = ccd.ul.estimate_aug_mask_prob(adata, input_feature = feature_list, n_samples = 10000, return_mean=False, plotting=True)\n</pre> # Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available) output_key = 'Concord' feature_list = ccd.ul.select_features(adata, n_top_features=10000, flavor='seurat_v3') # Determine augmentation mask probabilities based on estimated dropout rate from knn neighbors dropout_est = ccd.ul.estimate_aug_mask_prob(adata, input_feature = feature_list, n_samples = 10000, return_mean=False, plotting=True) <pre>Concord.utils.feature_selector - INFO - Selecting highly variable features with flavor seurat_v3...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (10000 features)...\nConcord - INFO - PCA embedding not found in adata.obsm. Running PCA...\nConcord - INFO - PCA completed.\n</pre> <pre>Concord - INFO - Average feature drop rate of nearest neighbors: 0.664814430564425\n</pre> In\u00a0[33]: Copied! <pre># Use median for concord run\nimport numpy as np\naug_prob = np.median(dropout_est)\n</pre> # Use median for concord run import numpy as np aug_prob = np.median(dropout_est) In\u00a0[38]: Copied! <pre>cross_tab = pd.crosstab(adata.obs['nuclei_extraction_date'], adata.obs['embryo_id'])\ncross_tab\n</pre> cross_tab = pd.crosstab(adata.obs['nuclei_extraction_date'], adata.obs['embryo_id']) cross_tab Out[38]: embryo_id 1 3 4 5 6 7 8 9 10 11 ... 59 60 61 62 63 64 65 66 67 68 nuclei_extraction_date 1 1113 590 900 1656 2000 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2614 2354 1928 2384 732 ... 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 ... 1843 2474 2557 2456 777 3253 1361 2702 1198 2038 <p>5 rows \u00d7 61 columns</p> <p>Based on the check above, we will use embryo_id as the 'domain_key' for batch integration.</p> In\u00a0[64]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=feature_list, \n                      domain_key='embryo_id', # \n                      latent_dim=300,\n                      encoder_dims=[1000],\n                      decoder_dims=[1000],\n                      augmentation_mask_prob = aug_prob, \n                      clr_temperature = .5, # Check out advanced usage to learn what this parameter controls\n                      p_intra_domain=1.0, \n                      seed=seed, \n                      inplace=False, \n                      verbose=True, \n                      device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a filem, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\nadata.obsm = cur_ccd.adata.obsm # If not inplace\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=feature_list,                        domain_key='embryo_id', #                        latent_dim=300,                       encoder_dims=[1000],                       decoder_dims=[1000],                       augmentation_mask_prob = aug_prob,                        clr_temperature = .5, # Check out advanced usage to learn what this parameter controls                       p_intra_domain=1.0,                        seed=seed,                        inplace=False,                        verbose=True,                        device=device)   # Encode data, saving the latent embedding in adata.obsm['Concord'] cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a filem, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") adata.obsm = cur_ccd.adata.obsm # If not inplace <pre>Concord - INFO - Setting sampler_knn to 2000 to be 1/50 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - INFO - Column 'embryo_id' is now of type: category\nConcord - INFO - Encoder input dim: 10000\nConcord - INFO - Decoder input dim: 308\nConcord - INFO - Model loaded to device: cuda:0\nConcord - INFO - Total number of parameters: 20635388\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (10000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 100000 samples. Data structure: ['input', 'domain', 'idx']\nConcord.model.dataloader - INFO - Using existing embedding 'X_pca' from adata.obsm\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss IVF index. nprobe=10\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.dataloader - INFO - Number of unique_domains: 61\nConcord.model.dataloader - INFO - Final p_intra_domain values: 1: 1.00, 3: 1.00, 4: 1.00, 5: 1.00, 6: 1.00, 7: 1.00, 8: 1.00, 9: 1.00, 10: 1.00, 11: 1.00, 12: 1.00, 13: 1.00, 14: 1.00, 15: 1.00, 16: 1.00, 17: 1.00, 19: 1.00, 20: 1.00, 21: 1.00, 22: 1.00, 24: 1.00, 25: 1.00, 26: 1.00, 27: 1.00, 28: 1.00, 29: 1.00, 31: 1.00, 33: 1.00, 34: 1.00, 35: 1.00, 36: 1.00, 37: 1.00, 38: 1.00, 39: 1.00, 40: 1.00, 41: 1.00, 42: 1.00, 43: 1.00, 44: 1.00, 46: 1.00, 47: 1.00, 48: 1.00, 49: 1.00, 50: 1.00, 51: 1.00, 52: 1.00, 53: 1.00, 55: 1.00, 56: 1.00, 57: 1.00, 58: 1.00, 59: 1.00, 60: 1.00, 61: 1.00, 62: 1.00, 63: 1.00, 64: 1.00, 65: 1.00, 66: 1.00, 67: 1.00, 68: 1.00\nConcord - INFO - Starting epoch 1/5\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>Epoch 0 Training: 1533it [00:57, 26.72it/s, loss=3.74]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 3.82, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.81, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 2/5\nConcord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1533/1533 [01:03&lt;00:00, 24.24it/s, loss=3.73]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 3.66, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.65, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 3/5\nConcord - INFO - Processing chunk 1/1 for epoch 3\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1533/1533 [00:56&lt;00:00, 27.32it/s, loss=3.69]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 3.63, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.62, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 4/5\nConcord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1533/1533 [00:59&lt;00:00, 25.69it/s, loss=3.67]</pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 3.61, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.60, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 5/5\nConcord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>Epoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1533/1533 [00:52&lt;00:00, 29.00it/s, loss=3.53]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 3.59, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.58, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Model saved to save/final_model.pth\nConcord - INFO - Final model saved at: save/final_model.pth; Configuration saved at: save/config.json.\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (10000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 100000 samples. Data structure: ['input', 'domain', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[69]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase']\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=.5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase'] ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=.5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <p>It is best to use 3D UMAP rather than 2D to visualize Concord latent, because 2D may not be enough to 'unpack' the complex structures learned by Concord, thus tends to break trajectories.</p> In\u00a0[70]: Copied! <pre>import plotly.io as pio\npio.renderers.default = 'notebook'\nccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'Main_cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata, basis=show_basis, color_by=col,\n        save_path=save_dir / f'{show_basis}_{file_suffix}.html',\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> import plotly.io as pio pio.renderers.default = 'notebook' ccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'Main_cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata, basis=show_basis, color_by=col,         save_path=save_dir / f'{show_basis}_{file_suffix}.html',         point_size=1, opacity=0.8, width=1500, height=1000     ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Concord_UMAP_3D']\nConcord - INFO - 3D plot saved to ../save/dev_concord_mouse_organogenesis_100k-Sep29/Concord_UMAP_3D_concord_mouse_organogenesis_100k_Sep29.html\n</pre> <p>Concord is able to learn both local and global structure. This means Concord have much higher resolution for each cell type in the dataset, and you can simply re-run UMAP on the global-learned latent of that cell type (without re-run Concord on that subset) to see the detailed structure for that cell type (which sometimes global UMAP cannot correctly embed). Here we demonstrate with two main trajectories: Mesenchymal trajectory and Neural tube and notochord trajectory.</p> <p>In practice, it is still recommended to subset and then run Concord because if you use variably expressed gene (VEG) selection for Concord input, it will further enrich for more cell sub-type specific genes/signals to enable even greater resolution within a cell type.</p> In\u00a0[84]: Copied! <pre>adata.obs['Main_trajectory'].value_counts()\n</pre> adata.obs['Main_trajectory'].value_counts() Out[84]: <pre>Main_trajectory\nMesenchymal trajectory                  43846\nNeural tube and notochord trajectory    41217\nEpithelial trajectory                    5144\nHaematopoiesis trajectory                3267\nEndothelial trajectory                   1918\nNeural crest 1                           1905\nNeural crest 2                           1676\nHepatocyte trajectory                     868\nNeural crest 3                            111\nLens trajectory                            48\nName: count, dtype: int64</pre> In\u00a0[\u00a0]: Copied! <pre>show_traj = 'Mesenchymal trajectory'\nadata_sub = adata[adata.obs['Main_trajectory'] == show_traj]\nccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase']\nccd.pl.plot_embedding(\n    adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',\n    save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.png\"\n)\n# output cleared due to github file size limit\n</pre> show_traj = 'Mesenchymal trajectory' adata_sub = adata[adata.obs['Main_trajectory'] == show_traj] ccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase'] ccd.pl.plot_embedding(     adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',     save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.png\" ) # output cleared due to github file size limit In\u00a0[103]: Copied! <pre>ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'Main_cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata_sub, basis=show_basis, color_by=col,\n        save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.html\",\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n# output cleared due to github size limit\n</pre> ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'Main_cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata_sub, basis=show_basis, color_by=col,         save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.html\",         point_size=1, opacity=0.8, width=1500, height=1000     ) # output cleared due to github size limit In\u00a0[\u00a0]: Copied! <pre>show_traj = 'Neural tube and notochord trajectory'\nadata_sub = adata[adata.obs['Main_trajectory'] == show_traj]\nccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase']\nccd.pl.plot_embedding(\n    adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',\n    save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.png\"\n)\n# output cleared due to github file size limit\n</pre> show_traj = 'Neural tube and notochord trajectory' adata_sub = adata[adata.obs['Main_trajectory'] == show_traj] ccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase'] ccd.pl.plot_embedding(     adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',     save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.png\" ) # output cleared due to github file size limit In\u00a0[105]: Copied! <pre>ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'Main_cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata_sub, basis=show_basis, color_by=col,\n        save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.html\",\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'Main_cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata_sub, basis=show_basis, color_by=col,         save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.html\",         point_size=1, opacity=0.8, width=1500, height=1000     ) In\u00a0[98]: Copied! <pre>feature_list = ccd.ul.select_features(adata_sub, n_top_features=10000, flavor='seurat_v3')\nsub_ccd = ccd.Concord(adata=adata_sub, \n                      input_feature=feature_list, \n                      domain_key='embryo_id', # \n                      latent_dim=100,\n                      encoder_dims=[1000],\n                      decoder_dims=[1000],\n                      augmentation_mask_prob = aug_prob, \n                      clr_temperature = .5, # Check out advanced usage to learn what this parameter controls\n                      p_intra_domain=1.0, \n                      seed=seed, \n                      inplace=False, \n                      verbose=False, \n                      device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\nsub_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a filem, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(sub_ccd.adata, save_dir / f\"obsm_{show_traj.replace(' ', '_')}_{file_suffix}.h5\")\nadata_sub.obsm = sub_ccd.adata.obsm # If not inplace\n</pre> feature_list = ccd.ul.select_features(adata_sub, n_top_features=10000, flavor='seurat_v3') sub_ccd = ccd.Concord(adata=adata_sub,                        input_feature=feature_list,                        domain_key='embryo_id', #                        latent_dim=100,                       encoder_dims=[1000],                       decoder_dims=[1000],                       augmentation_mask_prob = aug_prob,                        clr_temperature = .5, # Check out advanced usage to learn what this parameter controls                       p_intra_domain=1.0,                        seed=seed,                        inplace=False,                        verbose=False,                        device=device)   # Encode data, saving the latent embedding in adata.obsm['Concord'] sub_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a filem, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(sub_ccd.adata, save_dir / f\"obsm_{show_traj.replace(' ', '_')}_{file_suffix}.h5\") adata_sub.obsm = sub_ccd.adata.obsm # If not inplace <pre>Epoch 0 Training: 615it [00:23, 26.40it/s, loss=3.85]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 615/615 [00:20&lt;00:00, 29.47it/s, loss=3.96]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 615/615 [00:20&lt;00:00, 29.96it/s, loss=3.57]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 615/615 [00:20&lt;00:00, 29.69it/s, loss=3.52]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 615/615 [00:20&lt;00:00, 29.74it/s, loss=3.76]\n</pre> In\u00a0[99]: Copied! <pre>show_traj = 'Neural tube and notochord trajectory'\nccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase']\nccd.pl.plot_embedding(\n    adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',\n    save_path=save_dir / f\"{show_traj.replace(' ', '_')}_concord_zoom_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_traj = 'Neural tube and notochord trajectory' ccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase'] ccd.pl.plot_embedding(     adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',     save_path=save_dir / f\"{show_traj.replace(' ', '_')}_concord_zoom_{show_basis}_{file_suffix}.png\" ) In\u00a0[100]: Copied! <pre>ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=30, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'Main_cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata_sub, basis=show_basis, color_by=col,\n        save_path=save_dir / f\"{show_traj.replace(' ', '_')}_concord_zoom_{show_basis}_{file_suffix}.html\",\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=30, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'Main_cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata_sub, basis=show_basis, color_by=col,         save_path=save_dir / f\"{show_traj.replace(' ', '_')}_concord_zoom_{show_basis}_{file_suffix}.html\",         point_size=1, opacity=0.8, width=1500, height=1000     ) In\u00a0[80]: Copied! <pre>obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\"\nccd.ul.save_obsm_to_hdf5(adata, obsm_filename)\nadata.write_h5ad(f\"../data/mouse_organogenesis/{proj_name}_concord_{file_suffix}.h5ad\")\n</pre> obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\" ccd.ul.save_obsm_to_hdf5(adata, obsm_filename) adata.write_h5ad(f\"../data/mouse_organogenesis/{proj_name}_concord_{file_suffix}.h5ad\") <p>You can optionally convert the result to VisCello (https://github.com/kimpenn/VisCello) for interactive exploration.</p> In\u00a0[83]: Copied! <pre>ccd.ul.anndata_to_viscello(adata, save_dir / f\"cello_{proj_name}_{file_suffix}\", project_name = proj_name, organism='mmu')\n</pre> ccd.ul.anndata_to_viscello(adata, save_dir / f\"cello_{proj_name}_{file_suffix}\", project_name = proj_name, organism='mmu') <pre>VisCello project created at ../save/dev_concord_mouse_organogenesis_100k-Sep29/cello_concord_mouse_organogenesis_100k_concord_mouse_organogenesis_100k_Sep29\n</pre>"},{"location":"notebooks/concord_mouse_organogenesis_100k/#mouse-organogenesis-100k-subset","title":"Mouse organogenesis (100k subset)\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#basic-setup","title":"Basic setup\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#original-umap","title":"Original UMAP\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#define-feature-input-and-estimate-dropout-rate-in-data","title":"Define feature input and estimate dropout rate in data\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#run-concord","title":"Run Concord\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#visualize-concord-latent-with-umap","title":"Visualize Concord latent with UMAP\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#2d-umap","title":"2D UMAP\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#3d-umap","title":"3D UMAP\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#zoom-in-to-sub-trajectories-without-rerunning-concord","title":"Zoom in to sub-trajectories without rerunning Concord\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#mesenchymal-trajectory-global-latent","title":"Mesenchymal trajectory (Global latent)\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#neural-tube-and-notochord-trajectory-global-latent","title":"Neural tube and notochord trajectory (Global latent)\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#neural-tube-and-notochord-trajectory-re-run-concord-on-subset","title":"Neural tube and notochord trajectory (Re-run Concord on subset)\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#save-the-result","title":"Save the result\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/","title":"Pancreas dataset from scanpy tutorial","text":"<p>From Scanpy: \"The following data has been used in the scGen paper [Lotfollahi et al., 2019], has been used here, was curated here and can be downloaded from here (the BBKNN paper).</p> <p>It contains data for human pancreas from 4 different studies [Baron et al., 2016, Muraro et al., 2016, Segerstolpe et al., 2016, Wang et al., 2016], which have been used in the seminal papers on single-cell dataset integration [Butler et al., 2018, Haghverdi et al., 2018] and many times ever since.\"</p> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import Concord as ccd\nimport torch\nimport warnings\nimport scanpy as sc\nwarnings.filterwarnings('ignore')\n\nadata = sc.read(\"../data/scanpy_pancreas/pancreas.h5ad\", backup_url=\"https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1\")\n</pre> import Concord as ccd import torch import warnings import scanpy as sc warnings.filterwarnings('ignore')  adata = sc.read(\"../data/scanpy_pancreas/pancreas.h5ad\", backup_url=\"https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1\")  In\u00a0[3]: Copied! <pre>from pathlib import Path\nimport time\nproj_name = \"pancreas_scanpy\"\nsave_dir = Path(f\"../save/{proj_name}_{time.strftime('%b%d')}/\")\nsave_dir.mkdir(parents=True, exist_ok=True)\ndevice = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\nseed = 0\n</pre> from pathlib import Path import time proj_name = \"pancreas_scanpy\" save_dir = Path(f\"../save/{proj_name}_{time.strftime('%b%d')}/\") save_dir.mkdir(parents=True, exist_ok=True) device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu') seed = 0 In\u00a0[4]: Copied! <pre># adata.X is already scaled, but Concord expects non-negative values, either raw counts or log transformed counts are fine. \nadata = sc.AnnData(X=adata.raw.X, var=adata.raw.var, obs=adata.obs, obsm=adata.obsm, uns=adata.uns)\n</pre> # adata.X is already scaled, but Concord expects non-negative values, either raw counts or log transformed counts are fine.  adata = sc.AnnData(X=adata.raw.X, var=adata.raw.var, obs=adata.obs, obsm=adata.obsm, uns=adata.uns) In\u00a0[13]: Copied! <pre>sc.pp.highly_variable_genes(adata, n_top_genes=5000)  # Identify highly variable genes\nsc.pp.pca(adata)\nsc.pp.neighbors(adata, n_neighbors=30)  \nsc.tl.umap(adata, min_dist=0.1)\n</pre> sc.pp.highly_variable_genes(adata, n_top_genes=5000)  # Identify highly variable genes sc.pp.pca(adata) sc.pp.neighbors(adata, n_neighbors=30)   sc.tl.umap(adata, min_dist=0.1) In\u00a0[17]: Copied! <pre>show_basis = 'X_umap'\ncolor_by = [\"batch\", \"celltype\"]\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\"\nccd.pl.plot_embedding(\n    adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'X_umap' color_by = [\"batch\", \"celltype\"] file_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\" ccd.pl.plot_embedding(     adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <p>Use <code>pip install bbknn</code> to install the package if not installed.</p> In\u00a0[7]: Copied! <pre># subset adata to variable genes\nadata_hvg = adata[:, adata.var.highly_variable]\nsc.external.pp.bbknn(adata_hvg, batch_key=\"batch\")\n</pre> # subset adata to variable genes adata_hvg = adata[:, adata.var.highly_variable] sc.external.pp.bbknn(adata_hvg, batch_key=\"batch\") <pre>WARNING: consider updating your call to make use of `computation`\n</pre> In\u00a0[8]: Copied! <pre>sc.tl.umap(adata_hvg, min_dist=0.1)\nshow_basis = 'X_umap'\ncolor_by = [\"batch\", \"celltype\"]\nccd.pl.plot_embedding(\n    adata_hvg, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> sc.tl.umap(adata_hvg, min_dist=0.1) show_basis = 'X_umap' color_by = [\"batch\", \"celltype\"] ccd.pl.plot_embedding(     adata_hvg, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) In\u00a0[14]: Copied! <pre>feature_list = ccd.ul.select_features(adata, \n                                      n_top_features=5000, \n                                      flavor='seurat_v3', normalize=False, log1p=False)\n</pre> feature_list = ccd.ul.select_features(adata,                                        n_top_features=5000,                                        flavor='seurat_v3', normalize=False, log1p=False) In\u00a0[15]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=feature_list, # top 10000 VEGs selected above\n                      domain_key='batch', # key indicating batch\n                      augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7\n                      clr_temperature = 0.5, # temperature for NT-Xent loss\n                      seed=seed, # random seed\n                      p_intra_domain = 1.0, # probability of intra-domain sampling\n                      verbose=False, # print training progress\n                      inplace=False, # whether to modify original adata, set to False if you want to keep all expressions\n                      device=device # device to run on\n                      ) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\"\noutput_key = 'Concord'\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\nadata.obsm = cur_ccd.adata.obsm # If not inplace\n# Save the latent embedding to a file, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=feature_list, # top 10000 VEGs selected above                       domain_key='batch', # key indicating batch                       augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7                       clr_temperature = 0.5, # temperature for NT-Xent loss                       seed=seed, # random seed                       p_intra_domain = 1.0, # probability of intra-domain sampling                       verbose=False, # print training progress                       inplace=False, # whether to modify original adata, set to False if you want to keep all expressions                       device=device # device to run on                       )   # Encode data, saving the latent embedding in adata.obsm['Concord'] file_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\" output_key = 'Concord' cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  adata.obsm = cur_ccd.adata.obsm # If not inplace # Save the latent embedding to a file, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Epoch 0 Training: 227it [00:02, 86.19it/s, loss=4.35]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 227/227 [00:02&lt;00:00, 85.47it/s, loss=5.72]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 227/227 [00:02&lt;00:00, 84.74it/s, loss=3.95]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 227/227 [00:02&lt;00:00, 80.81it/s, loss=3.75]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 227/227 [00:02&lt;00:00, 85.29it/s, loss=3.78]\n</pre> In\u00a0[16]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\ncolor_by = [\"batch\", \"celltype\"]\nccd.pl.plot_embedding(\n    adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' color_by = [\"batch\", \"celltype\"] ccd.pl.plot_embedding(     adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <p>It is best to use 3D UMAP rather than 2D to visualize Concord latent, because 2D may not be enough to 'unpack' the complex structures learned by Concord, thus tends to break trajectories.</p> In\u00a0[18]: Copied! <pre>import plotly.io as pio\npio.renderers.default = 'notebook'\nccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\nshow_basis = f'{output_key}_UMAP_3D'\n#show_cols = ['log_nFeature', 'stage_numeric', 'group', 'cell_state', 'cell_type']\nshow_col = 'batch'\nccd.pl.plot_embedding_3d(\n    adata, basis=show_basis, color_by=show_col,\n    save_path=save_dir / f'{output_key}_UMAP_3D_{file_suffix}.html',\n    point_size=1, opacity=0.8, width=1500, height=1000\n)\n</pre> import plotly.io as pio pio.renderers.default = 'notebook' ccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean') show_basis = f'{output_key}_UMAP_3D' #show_cols = ['log_nFeature', 'stage_numeric', 'group', 'cell_state', 'cell_type'] show_col = 'batch' ccd.pl.plot_embedding_3d(     adata, basis=show_basis, color_by=show_col,     save_path=save_dir / f'{output_key}_UMAP_3D_{file_suffix}.html',     point_size=1, opacity=0.8, width=1500, height=1000 ) In\u00a0[19]: Copied! <pre>show_col = 'celltype'\nccd.pl.plot_embedding_3d(\n    adata, basis=show_basis, color_by=show_col,\n    save_path=save_dir / f'{output_key}_UMAP_3D_{file_suffix}.html',\n    point_size=1, opacity=0.8, width=1500, height=1000\n)\n</pre> show_col = 'celltype' ccd.pl.plot_embedding_3d(     adata, basis=show_basis, color_by=show_col,     save_path=save_dir / f'{output_key}_UMAP_3D_{file_suffix}.html',     point_size=1, opacity=0.8, width=1500, height=1000 ) In\u00a0[20]: Copied! <pre>from Concord.utils.doublet_utils import generate_synthetic_doublets\nadata_wt_syndoub = generate_synthetic_doublets(adata, doublet_synth_ratio=0.2, seed=seed, batch_key='batch', droplet_type_key = 'droplet_label', \n                                               mean=0.5, var=0.1, clip_range=(0.2, 0.8), combine_with_original=True, plot_histogram=True)\n</pre> from Concord.utils.doublet_utils import generate_synthetic_doublets adata_wt_syndoub = generate_synthetic_doublets(adata, doublet_synth_ratio=0.2, seed=seed, batch_key='batch', droplet_type_key = 'droplet_label',                                                 mean=0.5, var=0.1, clip_range=(0.2, 0.8), combine_with_original=True, plot_histogram=True) In\u00a0[21]: Copied! <pre>adata_wt_syndoub.obs['droplet_label'].value_counts()\n</pre> adata_wt_syndoub.obs['droplet_label'].value_counts() Out[21]: <pre>droplet_label\nsinglet    14693\ndoublet     2937\nName: count, dtype: int64</pre> In\u00a0[22]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata_wt_syndoub, \n                      input_feature=feature_list, # top VEGs selected above\n                      domain_key='batch', # key indicating batch\n                      augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7\n                      seed=seed, # random seed\n                      p_intra_domain = 1.0, # probability of intra-domain sampling\n                      verbose=True, # print training progress\n                      device=device, # device to run on\n                      inplace=False, # whether to modify original adata, set to False if you want to keep all expressions, set to True if you want to save memory\n                      # New doublet arguments\n                      train_frac = 0.9, # fraction of data to use for training\n                      use_classifier = True, # use classifier for doublet detection\n                      class_key = 'droplet_label', # key indicating if a cell is a doublet\n                      ) \n\nfile_suffix = f\"{proj_name}_wt_syndoub_{time.strftime('%b%d-%H%M')}\"\noutput_key = 'Concord_wt_syndoub'\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a file, so that it can be loaded later/\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata_wt_syndoub,                        input_feature=feature_list, # top VEGs selected above                       domain_key='batch', # key indicating batch                       augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7                       seed=seed, # random seed                       p_intra_domain = 1.0, # probability of intra-domain sampling                       verbose=True, # print training progress                       device=device, # device to run on                       inplace=False, # whether to modify original adata, set to False if you want to keep all expressions, set to True if you want to save memory                       # New doublet arguments                       train_frac = 0.9, # fraction of data to use for training                       use_classifier = True, # use classifier for doublet detection                       class_key = 'droplet_label', # key indicating if a cell is a doublet                       )   file_suffix = f\"{proj_name}_wt_syndoub_{time.strftime('%b%d-%H%M')}\" output_key = 'Concord_wt_syndoub' cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a file, so that it can be loaded later/ ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Concord - INFO - Setting sampler_knn to 352 to be 1/50 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - INFO - Column 'batch' is now of type: category\nConcord - INFO - Column 'droplet_label' is now of type: category\nConcord - INFO - Encoder input dim: 5000\nConcord - INFO - Decoder input dim: 40\nConcord - INFO - Classifier input dim: 32\nConcord - INFO - Model loaded to device: cuda:2\nConcord - INFO - Total number of parameters: 1296298\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (5000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 17630 samples. Data structure: ['input', 'domain', 'class', 'idx']\nConcord.model.dataloader - INFO - PCA embedding not found in adata.obsm. Running PCA...\nConcord.model.dataloader - INFO - PCA completed.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss IVF index. nprobe=10\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.dataloader - INFO - Number of unique_domains: 4\nConcord.model.dataloader - INFO - Final p_intra_domain values: 0: 1.00, 1: 1.00, 2: 1.00, 3: 1.00\nConcord.model.anndataset - INFO - Initialized dataset with 15867 samples. Data structure: ['input', 'domain', 'class', 'idx']\nConcord.model.anndataset - INFO - Initialized dataset with 1763 samples. Data structure: ['input', 'domain', 'class', 'idx']\nConcord - INFO - Starting epoch 1/5\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 0 Training: 273it [00:03, 75.94it/s, loss=4.27]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 4.80, MSE: 0.37, CLASS: 0.44, CONTRAST: 4.00, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   0 | Train accuracy:  0.83 | precision: 0: 0.64, 1: 0.84 | recall: 0: 0.11, 1: 0.99 | f1: 0: 0.18, 1: 0.91\n</pre> <pre>Epoch 0 Validation: 242it [00:01, 134.58it/s, loss=1.39] </pre> <pre>Concord - INFO - Epoch   0 | Val Loss: 1.84, MSE: 0.16, CLASS: 0.30, CONTRAST: 1.38, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   0 | Val accuracy:  0.88 | precision: 0: 0.82, 1: 0.88 | recall: 0: 0.32, 1: 0.99 | f1: 0: 0.46, 1: 0.93\nConcord - INFO - New best model found at epoch 1 with validation loss: 1.8390\nConcord - INFO - Starting epoch 2/5\nConcord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 273/273 [00:03&lt;00:00, 80.39it/s, loss=4.64]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 4.37, MSE: 0.21, CLASS: 0.37, CONTRAST: 3.79, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   1 | Train accuracy:  0.86 | precision: 0: 0.73, 1: 0.87 | recall: 0: 0.30, 1: 0.98 | f1: 0: 0.43, 1: 0.92\n</pre> <pre>Epoch 1 Validation:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 241/273 [00:01&lt;00:00, 167.33it/s, loss=1.79] </pre> <pre>Concord - INFO - Epoch   1 | Val Loss: 1.64, MSE: 0.14, CLASS: 0.28, CONTRAST: 1.22, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   1 | Val accuracy:  0.88 | precision: 0: 0.76, 1: 0.89 | recall: 0: 0.41, 1: 0.97 | f1: 0: 0.54, 1: 0.93\nConcord - INFO - New best model found at epoch 2 with validation loss: 1.6441\nConcord - INFO - Starting epoch 3/5\nConcord - INFO - Processing chunk 1/1 for epoch 3\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 273/273 [00:03&lt;00:00, 72.75it/s, loss=4.24]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 4.24, MSE: 0.18, CLASS: 0.35, CONTRAST: 3.71, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   2 | Train accuracy:  0.87 | precision: 0: 0.76, 1: 0.88 | recall: 0: 0.39, 1: 0.97 | f1: 0: 0.51, 1: 0.92\n</pre> <pre>Epoch 2 Validation:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 239/273 [00:01&lt;00:00, 155.66it/s, loss=1.38] </pre> <pre>Concord - INFO - Epoch   2 | Val Loss: 1.56, MSE: 0.12, CLASS: 0.26, CONTRAST: 1.18, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   2 | Val accuracy:  0.89 | precision: 0: 0.81, 1: 0.89 | recall: 0: 0.43, 1: 0.98 | f1: 0: 0.56, 1: 0.94\nConcord - INFO - New best model found at epoch 3 with validation loss: 1.5638\nConcord - INFO - Starting epoch 4/5\nConcord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 273/273 [00:03&lt;00:00, 74.27it/s, loss=4]   </pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 4.16, MSE: 0.17, CLASS: 0.34, CONTRAST: 3.66, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   3 | Train accuracy:  0.88 | precision: 0: 0.77, 1: 0.89 | recall: 0: 0.41, 1: 0.97 | f1: 0: 0.54, 1: 0.93\n</pre> <pre>Epoch 3 Validation:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 240/273 [00:01&lt;00:00, 150.97it/s, loss=1.16] </pre> <pre>Concord - INFO - Epoch   3 | Val Loss: 1.54, MSE: 0.12, CLASS: 0.26, CONTRAST: 1.16, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   3 | Val accuracy:  0.90 | precision: 0: 0.85, 1: 0.90 | recall: 0: 0.48, 1: 0.98 | f1: 0: 0.61, 1: 0.94\nConcord - INFO - New best model found at epoch 4 with validation loss: 1.5438\nConcord - INFO - Starting epoch 5/5\nConcord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 273/273 [00:03&lt;00:00, 72.97it/s, loss=3.94]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 4.11, MSE: 0.16, CLASS: 0.33, CONTRAST: 3.63, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   4 | Train accuracy:  0.88 | precision: 0: 0.76, 1: 0.89 | recall: 0: 0.43, 1: 0.97 | f1: 0: 0.55, 1: 0.93\n</pre> <pre>Epoch 4 Validation:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 236/273 [00:01&lt;00:00, 161.66it/s, loss=1.7]  </pre> <pre>Concord - INFO - Epoch   4 | Val Loss: 1.52, MSE: 0.11, CLASS: 0.27, CONTRAST: 1.13, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   4 | Val accuracy:  0.89 | precision: 0: 0.86, 1: 0.89 | recall: 0: 0.48, 1: 0.98 | f1: 0: 0.61, 1: 0.93\nConcord - INFO - New best model found at epoch 5 with validation loss: 1.5152\nConcord - INFO - Best model state loaded into the model before final save.\nConcord - INFO - Model saved to save/final_model.pth\nConcord - INFO - Final model saved at: save/final_model.pth; Configuration saved at: save/config.json.\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (5000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 17630 samples. Data structure: ['input', 'domain', 'class', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[23]: Copied! <pre>adata_wt_syndoub.obsm = cur_ccd.adata.obsm # If not inplace\nadata_wt_syndoub.obs = cur_ccd.adata.obs # If not inplace\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncrosstab_result = pd.crosstab(adata_wt_syndoub.obs[f'{output_key}_class_pred'], adata_wt_syndoub.obs[f'{output_key}_class_true'])\nprint(crosstab_result)\n\n# Plot confusion matrix as heatmap\nplt.figure(figsize=(4,2))\nsns.heatmap(crosstab_result, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.xlabel(\"True\")\nplt.ylabel(\"Predicted\")\nplt.title(\"Confusion Matrix\")\n</pre> adata_wt_syndoub.obsm = cur_ccd.adata.obsm # If not inplace adata_wt_syndoub.obs = cur_ccd.adata.obs # If not inplace import pandas as pd import seaborn as sns import matplotlib.pyplot as plt crosstab_result = pd.crosstab(adata_wt_syndoub.obs[f'{output_key}_class_pred'], adata_wt_syndoub.obs[f'{output_key}_class_true']) print(crosstab_result)  # Plot confusion matrix as heatmap plt.figure(figsize=(4,2)) sns.heatmap(crosstab_result, annot=True, fmt=\"d\", cmap=\"Blues\") plt.xlabel(\"True\") plt.ylabel(\"Predicted\") plt.title(\"Confusion Matrix\") <pre>Concord_wt_syndoub_class_true  doublet  singlet\nConcord_wt_syndoub_class_pred                  \ndoublet                           1473      286\nsinglet                           1464    14407\n</pre> Out[23]: <pre>Text(0.5, 1.0, 'Confusion Matrix')</pre> In\u00a0[28]: Copied! <pre>adata_wt_syndoub.obs\n</pre> adata_wt_syndoub.obs Out[28]: celltype sample n_genes batch n_counts louvain droplet_label Concord_wt_syndoub_class_true Concord_wt_syndoub_class_pred class_prob_doublet class_prob_singlet human1_lib1.final_cell_0001-0 acinar Baron 3526.0 0 22411.0 2 singlet singlet singlet 0.045450 0.954550 human1_lib1.final_cell_0002-0 acinar Baron 4201.0 0 27949.0 2 singlet singlet singlet 0.059101 0.940899 human1_lib1.final_cell_0003-0 acinar Baron 2119.0 0 16892.0 2 singlet singlet singlet 0.031126 0.968874 human1_lib1.final_cell_0004-0 acinar Baron 2956.0 0 19299.0 2 singlet singlet singlet 0.055361 0.944639 human1_lib1.final_cell_0005-0 acinar Baron 2715.0 0 15067.0 2 singlet singlet singlet 0.043646 0.956354 ... ... ... ... ... ... ... ... ... ... ... ... 2932 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.072913 0.927087 2933 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.135804 0.864196 2934 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.461214 0.538786 2935 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.071255 0.928745 2936 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.085542 0.914458 <p>17630 rows \u00d7 11 columns</p> In\u00a0[30]: Copied! <pre>ccd.ul.run_umap(adata_wt_syndoub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\ncolor_by = [\"batch\", \"celltype\", f'{output_key}_class_pred', f'{output_key}_class_true', f'class_prob_doublet']\nccd.pl.plot_embedding(\n    adata_wt_syndoub, basis=show_basis, color_by=color_by, figsize=(8, 5), dpi=300, ncols=3, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata_wt_syndoub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' color_by = [\"batch\", \"celltype\", f'{output_key}_class_pred', f'{output_key}_class_true', f'class_prob_doublet'] ccd.pl.plot_embedding(     adata_wt_syndoub, basis=show_basis, color_by=color_by, figsize=(8, 5), dpi=300, ncols=3, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) In\u00a0[31]: Copied! <pre>adata = adata_wt_syndoub[(adata_wt_syndoub.obs['droplet_label'] == 'singlet') &amp; (adata_wt_syndoub.obs['Concord_wt_syndoub_class_pred'] == 'singlet')]\nprint(adata.shape)\n</pre> adata = adata_wt_syndoub[(adata_wt_syndoub.obs['droplet_label'] == 'singlet') &amp; (adata_wt_syndoub.obs['Concord_wt_syndoub_class_pred'] == 'singlet')] print(adata.shape) <pre>(14407, 24516)\n</pre> In\u00a0[32]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=feature_list, # top VEGs selected above\n                      domain_key='batch', # key indicating batch\n                      augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7\n                      seed=seed, # random seed\n                      p_intra_domain = 1.0, # probability of intra-domain sampling\n                      verbose=True, # print training progress\n                      inplace=False, # whether to modify original adata, set to False if you want to keep all expressions, True if you want to save memory\n                      device=device # device to run on\n                      ) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\"\noutput_key = 'Concord'\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a file, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=feature_list, # top VEGs selected above                       domain_key='batch', # key indicating batch                       augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7                       seed=seed, # random seed                       p_intra_domain = 1.0, # probability of intra-domain sampling                       verbose=True, # print training progress                       inplace=False, # whether to modify original adata, set to False if you want to keep all expressions, True if you want to save memory                       device=device # device to run on                       )   # Encode data, saving the latent embedding in adata.obsm['Concord'] file_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\" output_key = 'Concord' cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a file, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Concord - INFO - Setting sampler_knn to 288 to be 1/50 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - INFO - Column 'batch' is already of type: category\nConcord - INFO - Unused levels dropped for column 'batch'.\nConcord - INFO - Encoder input dim: 5000\nConcord - INFO - Decoder input dim: 40\nConcord - INFO - Model loaded to device: cuda:2\nConcord - INFO - Total number of parameters: 1295112\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (5000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 14407 samples. Data structure: ['input', 'domain', 'idx']\nConcord.model.dataloader - INFO - Using existing embedding 'X_pca' from adata.obsm\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss IVF index. nprobe=10\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.dataloader - INFO - Number of unique_domains: 4\nConcord.model.dataloader - INFO - Final p_intra_domain values: 0: 1.00, 1: 1.00, 2: 1.00, 3: 1.00\nConcord - INFO - Starting epoch 1/5\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 0 Training: 223it [00:02, 78.84it/s, loss=3.92]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 4.47, MSE: 0.41, CLASS: 0.00, CONTRAST: 4.06, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 2/5\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 223/223 [00:02&lt;00:00, 74.70it/s, loss=3.92]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 4.11, MSE: 0.23, CLASS: 0.00, CONTRAST: 3.88, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 3/5\nConcord - INFO - Processing chunk 1/1 for epoch 3\n</pre> <pre>\n</pre> <pre>Concord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 223/223 [00:02&lt;00:00, 80.12it/s, loss=3.94]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 3.99, MSE: 0.19, CLASS: 0.00, CONTRAST: 3.80, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 4/5\nConcord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 223/223 [00:02&lt;00:00, 80.23it/s, loss=3.68]</pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 3.92, MSE: 0.18, CLASS: 0.00, CONTRAST: 3.74, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 5/5\nConcord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 223/223 [00:02&lt;00:00, 81.88it/s, loss=3.69]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 3.88, MSE: 0.17, CLASS: 0.00, CONTRAST: 3.71, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Model saved to save/final_model.pth\nConcord - INFO - Final model saved at: save/final_model.pth; Configuration saved at: save/config.json.\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (5000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 14407 samples. Data structure: ['input', 'domain', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[33]: Copied! <pre>adata.obsm = cur_ccd.adata.obsm # If not inplace\nccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\ncolor_by = [\"batch\", \"celltype\"]\nccd.pl.plot_embedding(\n    adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> adata.obsm = cur_ccd.adata.obsm # If not inplace ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' color_by = [\"batch\", \"celltype\"] ccd.pl.plot_embedding(     adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Concord_UMAP']\n</pre> In\u00a0[36]: Copied! <pre>obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\"\nccd.ul.save_obsm_to_hdf5(adata, obsm_filename)\nadata.write_h5ad(f\"{save_dir}/{proj_name}_{file_suffix}.h5ad\")\n</pre> obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\" ccd.ul.save_obsm_to_hdf5(adata, obsm_filename) adata.write_h5ad(f\"{save_dir}/{proj_name}_{file_suffix}.h5ad\") <p>You can optionally convert the result to VisCello (https://github.com/kimpenn/VisCello) for interactive exploration.</p> In\u00a0[69]: Copied! <pre>ccd.ul.anndata_to_viscello(adata, f'{save_dir}/cello_{proj_name}_{file_suffix}', project_name = proj_name, organism='dre')\n</pre> ccd.ul.anndata_to_viscello(adata, f'{save_dir}/cello_{proj_name}_{file_suffix}', project_name = proj_name, organism='dre') <pre>R was initialized outside of rpy2 (R_NilValue != NULL). Trying to use it nevertheless.\n</pre> <pre>VisCello project created at ../data/fish_tome//cello_concord_zebrafish_embryogenesis_concord_zebrafish_embryogenesis_Concordant_Oct03-1733\n</pre>"},{"location":"notebooks/concord_pancreas_scanpy/#pancreas-dataset-from-scanpy-tutorial","title":"Pancreas dataset from scanpy tutorial\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#basic-setup","title":"Basic setup\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#pca-umap","title":"PCA + UMAP\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#bbknn-used-by-scanpy-tutorial","title":"BBKNN used by scanpy tutorial\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#run-concord","title":"Run Concord\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#visualize-concord-latent-with-umap","title":"Visualize Concord latent with UMAP\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#2d-umap","title":"2D UMAP\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#3d-umap","title":"3D UMAP\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#doublet-calling-with-concord-optional","title":"Doublet calling with Concord (Optional)\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#simulate-synthetic-doublets","title":"Simulate synthetic doublets\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#run-on-the-singlet-set","title":"Run on the singlet set\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#save-the-result","title":"Save the result\u00b6","text":""},{"location":"notebooks/concord_pbmc3k/","title":"PBMC3k dataset, single batch","text":"In\u00a0[5]: Copied! <pre>import Concord as ccd\nimport scanpy as sc\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')\n\nadata = sc.datasets.pbmc3k_processed()\nadata = adata.raw.to_adata()  # Store raw counts in adata.X, by default Concord will run standard total count normalization and log transformation internally\n\n# Set device to cpu or to gpu (if your torch has been set up correctly to use GPU)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available)\nfeature_list = ccd.ul.select_features(adata, n_top_features=5000, flavor='seurat_v3')\n\n# Initialize Concord with an AnnData object, skip input_feature default to all features\ncur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, device=device, use_faiss=False, verbose=False) \n# If integrating data across batch, simply add the domain_key argument\n# cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='batch', device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key='Concord')\n</pre> import Concord as ccd import scanpy as sc import torch import warnings warnings.filterwarnings('ignore')  adata = sc.datasets.pbmc3k_processed() adata = adata.raw.to_adata()  # Store raw counts in adata.X, by default Concord will run standard total count normalization and log transformation internally  # Set device to cpu or to gpu (if your torch has been set up correctly to use GPU) device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  # Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available) feature_list = ccd.ul.select_features(adata, n_top_features=5000, flavor='seurat_v3')  # Initialize Concord with an AnnData object, skip input_feature default to all features cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, device=device, use_faiss=False, verbose=False)  # If integrating data across batch, simply add the domain_key argument # cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='batch', device=device)   # Encode data, saving the latent embedding in adata.obsm['Concord'] cur_ccd.encode_adata(input_layer_key='X_log1p', output_key='Concord') <pre>Concord.utils.feature_selector - INFO - Selecting highly variable features with flavor seurat_v3...\nConcord - WARNING - domain/batch information not found, all samples will be treated as from single domain/batch.\nConcord.model.dataloader - WARNING - Only one domain found in the data. Setting p_intra_domain to 1.0.\n</pre> <pre>Epoch 0 Training: 41it [00:01, 38.28it/s, loss=4.35]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:01&lt;00:00, 39.48it/s, loss=4.21]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:01&lt;00:00, 36.56it/s, loss=4.06]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:01&lt;00:00, 39.58it/s, loss=4.03]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 41.87it/s, loss=4.1] \n</pre> In\u00a0[6]: Copied! <pre>ccd.ul.run_umap(adata, source_key='Concord', umap_key='Concord_UMAP', n_components=2, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the UMAP embeddings\ncolor_by = ['n_genes', 'louvain'] # Choose which variables you want to visualize\nccd.pl.plot_embedding(\n    adata, basis='Concord_UMAP', color_by=color_by, figsize=(8, 4), dpi=600, ncols=2, font_size=6, point_size=10, legend_loc='on data',\n    save_path='Concord_UMAP.png'\n)\n</pre> ccd.ul.run_umap(adata, source_key='Concord', umap_key='Concord_UMAP', n_components=2, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the UMAP embeddings color_by = ['n_genes', 'louvain'] # Choose which variables you want to visualize ccd.pl.plot_embedding(     adata, basis='Concord_UMAP', color_by=color_by, figsize=(8, 4), dpi=600, ncols=2, font_size=6, point_size=10, legend_loc='on data',     save_path='Concord_UMAP.png' ) <p>Concord result is best visualized with 3D UMAPs because 2D UMAP sometimes is not enough to unpack the learned latent structures:</p> In\u00a0[8]: Copied! <pre>import plotly.io as pio\npio.renderers.default = 'notebook'\nccd.ul.run_umap(adata, source_key='Concord', umap_key='Concord_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'louvain'\nccd.pl.plot_embedding_3d(\n    adata, basis='Concord_UMAP_3D', color_by=col,\n    save_path='Concord_UMAP_3D.html',\n    point_size=1, opacity=0.8, width=1200, height=800\n)\n</pre> import plotly.io as pio pio.renderers.default = 'notebook' ccd.ul.run_umap(adata, source_key='Concord', umap_key='Concord_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'louvain' ccd.pl.plot_embedding_3d(     adata, basis='Concord_UMAP_3D', color_by=col,     save_path='Concord_UMAP_3D.html',     point_size=1, opacity=0.8, width=1200, height=800 )"},{"location":"notebooks/simulation_trajectory_full/","title":"Simulation using Concord","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import numpy as np\nimport scanpy as sc\nimport time\nfrom pathlib import Path\nimport torch\nimport Concord as ccd\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport matplotlib as mpl\n\nfrom matplotlib import font_manager, rcParams\ncustom_rc = {\n    'font.family': 'Arial',  # Set the desired font for this plot\n}\n\nmpl.rcParams['svg.fonttype'] = 'none'\nmpl.rcParams['pdf.fonttype'] = 42\n</pre> import numpy as np import scanpy as sc import time from pathlib import Path import torch import Concord as ccd import warnings warnings.filterwarnings('ignore') %matplotlib inline import matplotlib as mpl  from matplotlib import font_manager, rcParams custom_rc = {     'font.family': 'Arial',  # Set the desired font for this plot }  mpl.rcParams['svg.fonttype'] = 'none' mpl.rcParams['pdf.fonttype'] = 42 In\u00a0[3]: Copied! <pre>proj_name = \"simulation_trajectory\"\nsave_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\"\nsave_dir = Path(save_dir)\nsave_dir.mkdir(parents=True, exist_ok=True)\n\ndata_dir = f\"../data/{proj_name}/\"\ndata_dir = Path(data_dir)\ndata_dir.mkdir(parents=True, exist_ok=True)\ndevice = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\nprint(device)\nseed = 0\nccd.ul.set_seed(seed)\n\nfile_suffix = f\"{time.strftime('%b%d-%H%M')}\"\nfile_suffix\n</pre> proj_name = \"simulation_trajectory\" save_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\" save_dir = Path(save_dir) save_dir.mkdir(parents=True, exist_ok=True)  data_dir = f\"../data/{proj_name}/\" data_dir = Path(data_dir) data_dir.mkdir(parents=True, exist_ok=True) device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu') print(device) seed = 0 ccd.ul.set_seed(seed)  file_suffix = f\"{time.strftime('%b%d-%H%M')}\" file_suffix <pre>cpu\n</pre> Out[3]: <pre>'Feb16-1614'</pre> In\u00a0[4]: Copied! <pre>state_key = 'time'\nbatch_key = 'batch'\nstate_type = 'trajectory'\nbatch_type = 'batch_specific_features'\ndistribution = 'normal'\nleiden_key = 'leiden_no_noise'\n</pre> state_key = 'time' batch_key = 'batch' state_type = 'trajectory' batch_type = 'batch_specific_features' distribution = 'normal' leiden_key = 'leiden_no_noise' In\u00a0[46]: Copied! <pre>from Concord.utils.simulation import Simulation\n\n# Create an instance of the Simulation class\n\nsim = Simulation(n_cells=1000, n_genes=100, n_batches=2, n_states=3, \n                 state_type=state_type, \n                 state_distribution = distribution, \n                 state_level=10, \n                 state_min_level=0,\n                 state_dispersion=2.0, \n                 program_structure='linear_bidirectional',\n                 program_on_time_fraction=0.1,\n                 trajectory_program_num=5,\n                 trajectory_cell_block_size_ratio=0.6,\n                 trajectory_loop_to=None,\n                 batch_distribution = distribution,\n                 batch_type=batch_type, \n                 batch_level=[10,10], \n                 batch_dispersion=[2.0, 2.0], \n                 non_neg=True, to_int=True,\n                 seed=42)\n\n# Generate the simulated data\nadata, adata_state = sim.simulate_data()\n</pre> from Concord.utils.simulation import Simulation  # Create an instance of the Simulation class  sim = Simulation(n_cells=1000, n_genes=100, n_batches=2, n_states=3,                   state_type=state_type,                   state_distribution = distribution,                   state_level=10,                   state_min_level=0,                  state_dispersion=2.0,                   program_structure='linear_bidirectional',                  program_on_time_fraction=0.1,                  trajectory_program_num=5,                  trajectory_cell_block_size_ratio=0.6,                  trajectory_loop_to=None,                  batch_distribution = distribution,                  batch_type=batch_type,                   batch_level=[10,10],                   batch_dispersion=[2.0, 2.0],                   non_neg=True, to_int=True,                  seed=42)  # Generate the simulated data adata, adata_state = sim.simulate_data()  <pre>Concord.utils.simulation - INFO - Simulating trajectory with 3 states, distribution: normal with mean expression 10 and dispersion 2.0.\nConcord.utils.simulation - INFO - Simulating batch-specific features effect on batch_1 by appending a set of batch-specific genes with normal distributed value with level 10 and dispersion 2.0.\nConcord.utils.simulation - INFO - Simulating batch-specific features effect on batch_2 by appending a set of batch-specific genes with normal distributed value with level 10 and dispersion 2.0.\n</pre> In\u00a0[47]: Copied! <pre>ccd.pl.heatmap_with_annotations(adata_state, val='no_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state', save_path=save_dir/f'true_state_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300)\nccd.pl.heatmap_with_annotations(adata_state, val='wt_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state with noise', save_path=save_dir/f'true_state_with_noise_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300)\nccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Simulated data with batch signal', save_path=save_dir/f'simulated_data_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300)\n</pre> ccd.pl.heatmap_with_annotations(adata_state, val='no_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state', save_path=save_dir/f'true_state_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300) ccd.pl.heatmap_with_annotations(adata_state, val='wt_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state with noise', save_path=save_dir/f'true_state_with_noise_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300) ccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Simulated data with batch signal', save_path=save_dir/f'simulated_data_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300) Out[47]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f094c765ca0&gt;</pre> In\u00a0[48]: Copied! <pre>ccd.ul.run_pca(adata_state, source_key='no_noise', result_key='PCA_no_noise', n_pc=30, random_state=seed)\nccd.ul.run_umap(adata_state, source_key='PCA_no_noise', result_key='UMAP_no_noise', random_state=seed)\n</pre> ccd.ul.run_pca(adata_state, source_key='no_noise', result_key='PCA_no_noise', n_pc=30, random_state=seed) ccd.ul.run_umap(adata_state, source_key='PCA_no_noise', result_key='UMAP_no_noise', random_state=seed) <pre>Concord - INFO - PCA performed on source data with 30 components\nConcord - INFO - PCA embedding stored in adata.obsm['PCA_no_noise']\nConcord - INFO - UMAP embedding stored in adata.obsm['UMAP_no_noise']\n</pre> In\u00a0[49]: Copied! <pre>sc.pp.neighbors(adata_state, use_rep='PCA_no_noise', n_neighbors=30, random_state=seed)\nsc.tl.leiden(adata_state, resolution=1.0, key_added=leiden_key, random_state=seed)\nadata.obs[leiden_key] = adata_state.obs[leiden_key]\n</pre> sc.pp.neighbors(adata_state, use_rep='PCA_no_noise', n_neighbors=30, random_state=seed) sc.tl.leiden(adata_state, resolution=1.0, key_added=leiden_key, random_state=seed) adata.obs[leiden_key] = adata_state.obs[leiden_key] In\u00a0[26]: Copied! <pre>show_basis = 'PCA_no_noise'\nshow_cols = [state_key, leiden_key, batch_key]\n\nccd.pl.plot_embedding(\n    adata_state, show_basis, show_cols, figsize=(7.5,2.5), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data', rasterized=False,\n    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.pdf\"\n)\n</pre> show_basis = 'PCA_no_noise' show_cols = [state_key, leiden_key, batch_key]  ccd.pl.plot_embedding(     adata_state, show_basis, show_cols, figsize=(7.5,2.5), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data', rasterized=False,     save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.pdf\" ) In\u00a0[51]: Copied! <pre>show_basis = 'UMAP_no_noise'\nshow_cols = [state_key, leiden_key]\n\nccd.pl.plot_embedding(\n    adata_state, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'UMAP_no_noise' show_cols = [state_key, leiden_key]  ccd.pl.plot_embedding(     adata_state, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',     save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.png\" ) In\u00a0[52]: Copied! <pre>adata_state.X = adata_state.layers['wt_noise'].copy()\nccd.ul.run_pca(adata_state, source_key='wt_noise', result_key='PCA_wt_noise', n_pc=30, random_state=seed)\nccd.ul.run_umap(adata_state, source_key='PCA_wt_noise', result_key='UMAP_wt_noise', random_state=seed)\n</pre> adata_state.X = adata_state.layers['wt_noise'].copy() ccd.ul.run_pca(adata_state, source_key='wt_noise', result_key='PCA_wt_noise', n_pc=30, random_state=seed) ccd.ul.run_umap(adata_state, source_key='PCA_wt_noise', result_key='UMAP_wt_noise', random_state=seed) <pre>Concord - INFO - PCA performed on source data with 30 components\nConcord - INFO - PCA embedding stored in adata.obsm['PCA_wt_noise']\nConcord - INFO - UMAP embedding stored in adata.obsm['UMAP_wt_noise']\n</pre> In\u00a0[25]: Copied! <pre>show_basis = 'PCA_wt_noise'\nshow_cols = [state_key, leiden_key, batch_key]\n\nccd.pl.plot_embedding(\n    adata_state, show_basis, show_cols, figsize=(7.5,2.5), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data', rasterized=False,\n    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.pdf\"\n)\n</pre> show_basis = 'PCA_wt_noise' show_cols = [state_key, leiden_key, batch_key]  ccd.pl.plot_embedding(     adata_state, show_basis, show_cols, figsize=(7.5,2.5), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data', rasterized=False,     save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.pdf\" ) In\u00a0[54]: Copied! <pre>show_basis = 'UMAP_wt_noise'\nshow_cols = [state_key, leiden_key]\n\nccd.pl.plot_embedding(\n    adata_state, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'UMAP_wt_noise' show_cols = [state_key, leiden_key]  ccd.pl.plot_embedding(     adata_state, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',     save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.png\" ) In\u00a0[55]: Copied! <pre>n_pcs = min(adata.n_obs, adata.n_vars)-1\nsc.pp.pca(adata, n_comps=n_pcs)\nsc.pp.neighbors(adata, n_neighbors=30, n_pcs=n_pcs)\nsc.tl.umap(adata, min_dist=0.5)\nadata.obsm[\"Unintegrated\"] = adata.obsm[\"X_pca\"]\n</pre> n_pcs = min(adata.n_obs, adata.n_vars)-1 sc.pp.pca(adata, n_comps=n_pcs) sc.pp.neighbors(adata, n_neighbors=30, n_pcs=n_pcs) sc.tl.umap(adata, min_dist=0.5) adata.obsm[\"Unintegrated\"] = adata.obsm[\"X_pca\"] In\u00a0[56]: Copied! <pre>show_basis = 'X_pca'\nshow_cols = [state_key, batch_key, leiden_key]\n\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n    save_path=save_dir / f\"wtbatch_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'X_pca' show_cols = [state_key, batch_key, leiden_key]  ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',     save_path=save_dir / f\"wtbatch_{show_basis}_{file_suffix}.png\" ) In\u00a0[57]: Copied! <pre>show_basis = 'X_umap'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n    save_path=save_dir / f\"wtbatch_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'X_umap' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',     save_path=save_dir / f\"wtbatch_{show_basis}_{file_suffix}.png\" ) In\u00a0[100]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=None, \n                      batch_size=64,\n                      n_epochs=10,\n                      domain_key=batch_key, # key indicating batch\n                      seed=seed, # random seed\n                      verbose=False, # print training progress\n                      device=device, # device to run on\n                      save_dir=save_dir # directory to save model checkpoints\n                      ) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\noutput_key = 'Concord'\n\ncur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)\n\n# Save the latent embedding to a file, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=None,                        batch_size=64,                       n_epochs=10,                       domain_key=batch_key, # key indicating batch                       seed=seed, # random seed                       verbose=False, # print training progress                       device=device, # device to run on                       save_dir=save_dir # directory to save model checkpoints                       )   # Encode data, saving the latent embedding in adata.obsm['Concord'] output_key = 'Concord'  cur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)  # Save the latent embedding to a file, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Concord - WARNING - No input feature list provided. It is recommended to first select features using the command `concord.ul.select_features()`.\n</pre> <pre>WARNING clustering 1000 points to 31 centroids: please provide at least 1209 training points\n</pre> <pre>p_intra_knn: 0.3\n</pre> <pre>Epoch 0 Training: 14it [00:00, 64.20it/s, loss=4.07]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 70.18it/s, loss=3.96]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 74.94it/s, loss=3.89]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 80.20it/s, loss=3.78]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 79.21it/s, loss=3.78]\nEpoch 5 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 71.98it/s, loss=3.75]\nEpoch 6 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 68.10it/s, loss=3.8]\nEpoch 7 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 42.68it/s, loss=3.77]\nEpoch 8 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 42.76it/s, loss=3.82]\nEpoch 9 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 36.47it/s, loss=3.78]\n</pre> In\u00a0[101]: Copied! <pre>ccd.pl.heatmap_with_annotations(adata, val='Concord', obs_keys=[state_key, batch_key], \n                                cluster_cols=True, cluster_rows=True, cmap='viridis', \n                                pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,\n                                save_path=save_dir/f'Concord_latent_heatmap_{file_suffix}.png')\n</pre> ccd.pl.heatmap_with_annotations(adata, val='Concord', obs_keys=[state_key, batch_key],                                  cluster_cols=True, cluster_rows=True, cmap='viridis',                                  pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,                                 save_path=save_dir/f'Concord_latent_heatmap_{file_suffix}.png') Out[101]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f081402c070&gt;</pre> In\u00a0[102]: Copied! <pre># Compute the correlation matrix\ncos_mtx = ccd.ul.cosine_sim(adata.obsm['Concord'])\nccd.pl.heatmap_with_annotations(adata, val=cos_mtx,\n                                obs_keys=[state_key, batch_key], cluster_cols=True, cluster_rows=True, cmap='viridis', save_path=save_dir/f'Concord_cosine_{file_suffix}.png')\n</pre> # Compute the correlation matrix cos_mtx = ccd.ul.cosine_sim(adata.obsm['Concord']) ccd.pl.heatmap_with_annotations(adata, val=cos_mtx,                                 obs_keys=[state_key, batch_key], cluster_cols=True, cluster_rows=True, cmap='viridis', save_path=save_dir/f'Concord_cosine_{file_suffix}.png') Out[102]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f07f40f1b20&gt;</pre> In\u00a0[103]: Copied! <pre>n_pc = min(adata.obsm[output_key].shape[1], adata.shape[0]) - 1\nccd.ul.run_pca(adata, source_key=output_key, result_key=f'{output_key}_PCA', n_pc=n_pc, random_state=seed)\nshow_basis = f'{output_key}'\nshow_cols = [state_key, batch_key, leiden_key]\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> n_pc = min(adata.obsm[output_key].shape[1], adata.shape[0]) - 1 ccd.ul.run_pca(adata, source_key=output_key, result_key=f'{output_key}_PCA', n_pc=n_pc, random_state=seed) show_basis = f'{output_key}' show_cols = [state_key, batch_key, leiden_key] ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) In\u00a0[\u00a0]: Copied! <pre>sc.pp.neighbors(adata, n_neighbors=30, use_rep = 'Concord')\nccd.ul.run_umap(adata_b1, source_key='Concord', result_key='Concord_UMAP_2D', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\n\nshow_cols = [state_key, batch_key, leiden_key]\nshow_basis = 'Concord_UMAP_2D'   \nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    #pal = {'cluster':'Set1', 'batch':'Set2', 'leiden':'tab20'},\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> sc.pp.neighbors(adata, n_neighbors=30, use_rep = 'Concord') ccd.ul.run_umap(adata_b1, source_key='Concord', result_key='Concord_UMAP_2D', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)  show_cols = [state_key, batch_key, leiden_key] show_basis = 'Concord_UMAP_2D'    ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     #pal = {'cluster':'Set1', 'batch':'Set2', 'leiden':'tab20'},     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" )  In\u00a0[105]: Copied! <pre>adata.write_h5ad(data_dir / f\"adata_{file_suffix}.h5ad\") \nadata_state.write_h5ad(data_dir / f\"adata_state_{file_suffix}.h5ad\")\n</pre> adata.write_h5ad(data_dir / f\"adata_{file_suffix}.h5ad\")  adata_state.write_h5ad(data_dir / f\"adata_state_{file_suffix}.h5ad\") In\u00a0[106]: Copied! <pre>file_suffix\n</pre> file_suffix Out[106]: <pre>'Nov16-1334'</pre> In\u00a0[8]: Copied! <pre>file_suffix = f\"{time.strftime('%b%d-%H%M')}\"\nccd.set_verbose_mode(True)\nshow_cols = [state_key, batch_key]\ntimer = ccd.ul.Timer()\ntime_log = {}\n</pre> file_suffix = f\"{time.strftime('%b%d-%H%M')}\" ccd.set_verbose_mode(True) show_cols = [state_key, batch_key] timer = ccd.ul.Timer() time_log = {} In\u00a0[69]: Copied! <pre>output_key = 'Scanorama'\n\nwith timer:\n    ccd.ul.run_scanorama(adata, batch_key=\"batch\", output_key=output_key, return_corrected=True)\n\ntime_log[output_key] = timer.interval\nccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> output_key = 'Scanorama'  with timer:     ccd.ul.run_scanorama(adata, batch_key=\"batch\", output_key=output_key, return_corrected=True)  time_log[output_key] = timer.interval ccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Found 120 genes among all datasets\n[[0.    0.992]\n [0.    0.   ]]\nProcessing datasets (0, 1)\nFound 120 genes among all datasets\n[[0.    0.992]\n [0.    0.   ]]\nProcessing datasets (0, 1)\n</pre> In\u00a0[70]: Copied! <pre># Plot heatmap of Scanorama corrected data\nccd.pl.heatmap_with_annotations(adata, val=f'{output_key}_corrected', obs_keys=[state_key, batch_key], \n                                cluster_cols=False, cluster_rows=False, cmap='viridis', \n                                pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,\n                                save_path=save_dir/f'{output_key}_corrected_heatmap_{file_suffix}.png')\n</pre> # Plot heatmap of Scanorama corrected data ccd.pl.heatmap_with_annotations(adata, val=f'{output_key}_corrected', obs_keys=[state_key, batch_key],                                  cluster_cols=False, cluster_rows=False, cmap='viridis',                                  pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,                                 save_path=save_dir/f'{output_key}_corrected_heatmap_{file_suffix}.png') Out[70]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f08ec5a8b50&gt;</pre> In\u00a0[71]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Scanorama_UMAP']\n</pre> In\u00a0[72]: Copied! <pre>output_key = 'Liger'\nadata.layers[\"counts\"] = adata.X.copy()\nwith timer:\n    ccd.ul.run_liger(adata, batch_key=\"batch\", count_layer=\"counts\", output_key=output_key, k=30, return_corrected=True)\n\ntime_log[output_key] = timer.interval\nccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> output_key = 'Liger' adata.layers[\"counts\"] = adata.X.copy() with timer:     ccd.ul.run_liger(adata, batch_key=\"batch\", count_layer=\"counts\", output_key=output_key, k=30, return_corrected=True)  time_log[output_key] = timer.interval ccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:04&lt;00:00,  6.75it/s]\n</pre> In\u00a0[73]: Copied! <pre># Plot heatmap of Scanorama corrected data\nccd.pl.heatmap_with_annotations(adata, val=f'{output_key}_corrected', obs_keys=[state_key, batch_key], \n                                cluster_cols=False, cluster_rows=False, cmap='viridis', \n                                pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,\n                                save_path=save_dir/f'{output_key}_corrected_heatmap_{file_suffix}.png')\n</pre> # Plot heatmap of Scanorama corrected data ccd.pl.heatmap_with_annotations(adata, val=f'{output_key}_corrected', obs_keys=[state_key, batch_key],                                  cluster_cols=False, cluster_rows=False, cmap='viridis',                                  pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,                                 save_path=save_dir/f'{output_key}_corrected_heatmap_{file_suffix}.png') Out[73]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f094c2c97f0&gt;</pre> In\u00a0[74]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Liger_UMAP']\n</pre> In\u00a0[75]: Copied! <pre>output_key = 'Harmony'\nwith timer:\n    ccd.ul.run_harmony(adata, batch_key=\"batch\", input_key='X_pca', output_key=output_key)\n\ntime_log[output_key] = timer.interval\nccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> output_key = 'Harmony' with timer:     ccd.ul.run_harmony(adata, batch_key=\"batch\", input_key='X_pca', output_key=output_key)  time_log[output_key] = timer.interval ccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>\tInitialization is completed.\n\tCompleted 1 / 10 iteration(s).\n\tCompleted 2 / 10 iteration(s).\n\tCompleted 3 / 10 iteration(s).\n\tCompleted 4 / 10 iteration(s).\n\tCompleted 5 / 10 iteration(s).\n\tCompleted 6 / 10 iteration(s).\n\tCompleted 7 / 10 iteration(s).\nReach convergence after 7 iteration(s).\n</pre> In\u00a0[76]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Harmony_UMAP']\n</pre> In\u00a0[77]: Copied! <pre>output_key = 'scVI'\ntransform_batch = 'batch_1'\nwith timer:\n    scvi_vae = ccd.ul.run_scvi(adata, batch_key=\"batch\", output_key=output_key, return_model=True, return_corrected=True, transform_batch=transform_batch)\n\ntime_log[output_key] = timer.interval\nccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> output_key = 'scVI' transform_batch = 'batch_1' with timer:     scvi_vae = ccd.ul.run_scvi(adata, batch_key=\"batch\", output_key=output_key, return_model=True, return_corrected=True, transform_batch=transform_batch)  time_log[output_key] = timer.interval ccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n</pre> <pre>Epoch 400/400: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 400/400 [00:41&lt;00:00,  9.17it/s, v_num=1, train_loss_step=196, train_loss_epoch=196]</pre> <pre>`Trainer.fit` stopped: `max_epochs=400` reached.\n</pre> <pre>Epoch 400/400: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 400/400 [00:41&lt;00:00,  9.66it/s, v_num=1, train_loss_step=196, train_loss_epoch=196]\n</pre> In\u00a0[78]: Copied! <pre>ccd.pl.heatmap_with_annotations(adata, val=f'{output_key}_corrected_{transform_batch}', obs_keys=[state_key, batch_key], \n                                cluster_cols=False, cluster_rows=False, cmap='viridis', \n                                pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,\n                                save_path=save_dir/f'{output_key}_{transform_batch}_corrected_heatmap_{file_suffix}.png')\n</pre> ccd.pl.heatmap_with_annotations(adata, val=f'{output_key}_corrected_{transform_batch}', obs_keys=[state_key, batch_key],                                  cluster_cols=False, cluster_rows=False, cmap='viridis',                                  pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,                                 save_path=save_dir/f'{output_key}_{transform_batch}_corrected_heatmap_{file_suffix}.png') Out[78]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f08b4238bb0&gt;</pre> In\u00a0[79]: Copied! <pre>output_key = 'scVI'\nccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> output_key = 'scVI' ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['scVI_UMAP']\n</pre> In\u00a0[80]: Copied! <pre>output_key = 'scANVI'\nwith timer:\n    ccd.ul.run_scanvi(adata, batch_key=\"batch\", labels_key=leiden_key, output_key=output_key, scvi_model=scvi_vae, return_corrected=True, transform_batch=transform_batch)\n\ntime_log[output_key] = timer.interval\nccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> output_key = 'scANVI' with timer:     ccd.ul.run_scanvi(adata, batch_key=\"batch\", labels_key=leiden_key, output_key=output_key, scvi_model=scvi_vae, return_corrected=True, transform_batch=transform_batch)  time_log[output_key] = timer.interval ccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>INFO     Training for 20 epochs.                                                                                   \n</pre> <pre>Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n</pre> <pre>Epoch 20/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:05&lt;00:00,  4.35it/s, v_num=1, train_loss_step=310, train_loss_epoch=232]</pre> <pre>`Trainer.fit` stopped: `max_epochs=20` reached.\n</pre> <pre>Epoch 20/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:05&lt;00:00,  3.73it/s, v_num=1, train_loss_step=310, train_loss_epoch=232]\n</pre> In\u00a0[81]: Copied! <pre># Plot heatmap of Scanorama corrected data\nccd.pl.heatmap_with_annotations(adata, val=f'{output_key}_corrected_{transform_batch}', obs_keys=[state_key, batch_key], \n                                cluster_cols=False, cluster_rows=False, cmap='viridis', \n                                pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,\n                                save_path=save_dir/f'{output_key}_{transform_batch}_corrected_heatmap_{file_suffix}.png')\n</pre> # Plot heatmap of Scanorama corrected data ccd.pl.heatmap_with_annotations(adata, val=f'{output_key}_corrected_{transform_batch}', obs_keys=[state_key, batch_key],                                  cluster_cols=False, cluster_rows=False, cmap='viridis',                                  pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,                                 save_path=save_dir/f'{output_key}_{transform_batch}_corrected_heatmap_{file_suffix}.png') Out[81]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f08f4786cd0&gt;</pre> In\u00a0[82]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['scANVI_UMAP']\n</pre> In\u00a0[6]: Copied! <pre>min_p_intra_domain=0.95\n</pre> min_p_intra_domain=0.95 In\u00a0[28]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=None, \n                      batch_size=64,\n                      n_epochs=10,\n                      domain_key=batch_key, # key indicating batch\n                      min_p_intra_domain=min_p_intra_domain, # probability of sampling intra-domain pairs\n                      seed=seed, # random seed\n                      verbose=True, # print training progress\n                      device=device, # device to run on\n                      save_dir=save_dir # directory to save model checkpoints\n                      ) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\noutput_key = 'Concord'\nwith timer:\n    cur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)\n    \ntime_log[output_key] = timer.interval\n\n# Save the latent embedding to a file, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=None,                        batch_size=64,                       n_epochs=10,                       domain_key=batch_key, # key indicating batch                       min_p_intra_domain=min_p_intra_domain, # probability of sampling intra-domain pairs                       seed=seed, # random seed                       verbose=True, # print training progress                       device=device, # device to run on                       save_dir=save_dir # directory to save model checkpoints                       )   # Encode data, saving the latent embedding in adata.obsm['Concord'] output_key = 'Concord' with timer:     cur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)      time_log[output_key] = timer.interval  # Save the latent embedding to a file, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Concord - INFO - Setting sampler_knn to 100 to be 1/10 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - WARNING - No input feature list provided. It is recommended to first select features using the command `concord.ul.select_features()`.\nConcord - INFO - Proceeding with all 120 features in the dataset.\nConcord - INFO - Column 'batch' is already of type: category\nConcord - INFO - Unused levels dropped for column 'batch'.\nConcord - INFO - Encoder input dim: 120\nConcord - INFO - Model loaded to device: cuda:3\nConcord - INFO - Total number of parameters: 19952\nConcord.model.anndataset - INFO - Initialized dataset with 1000 samples. Data structure: ['input', 'domain', 'idx']\nConcord - INFO - Using existing embedding 'X_pca' from adata.obsm\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss IVF index. nprobe=10\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.dataloader - INFO - Number of unique_domains: 2\n</pre> <pre>WARNING clustering 1000 points to 31 centroids: please provide at least 1209 training points\n</pre> <pre>Concord.model.dataloader - INFO - Calculating each domain's coverage of the global manifold using X_pca.\nConcord.model.dataloader - INFO - Converting coverage {'batch_1': 0.53, 'batch_2': 0.545} to p_intra_domain...\nConcord.model.dataloader - INFO - Final p_intra_domain values: batch_1: 0.98, batch_2: 0.98\np_intra_knn: 0.5\nConcord - INFO - Starting epoch 1/10\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 0 Training: 14it [00:00, 103.37it/s, loss=4.19]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 4.38, MSE: 0.00, CLASS: 0.00, CONTRAST: 4.38, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 2/10\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 85.60it/s, loss=4.08]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 4.10, MSE: 0.00, CLASS: 0.00, CONTRAST: 4.10, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 3/10\nConcord - INFO - Processing chunk 1/1 for epoch 3\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 98.71it/s, loss=4.01]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 4.06, MSE: 0.00, CLASS: 0.00, CONTRAST: 4.06, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 4/10\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 101.67it/s, loss=4.01]</pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 4.03, MSE: 0.00, CLASS: 0.00, CONTRAST: 4.03, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 5/10\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 102.88it/s, loss=3.97]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 3.95, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.95, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 6/10\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 6\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 5 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 97.58it/s, loss=4.02]</pre> <pre>Concord - INFO - Epoch   5 | Train Loss: 3.92, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.92, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 7/10\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 7\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 6 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 99.52it/s, loss=3.93]</pre> <pre>Concord - INFO - Epoch   6 | Train Loss: 3.87, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.87, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 8/10\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 8\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 7 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 103.13it/s, loss=3.79]</pre> <pre>Concord - INFO - Epoch   7 | Train Loss: 3.89, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.89, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 9/10\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 9\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 8 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 99.00it/s, loss=3.89]</pre> <pre>Concord - INFO - Epoch   8 | Train Loss: 3.84, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.84, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 10/10\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 10\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 9 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 99.82it/s, loss=3.8] </pre> <pre>Concord - INFO - Epoch   9 | Train Loss: 3.87, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.87, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Model saved to ../save/dev_simulation_trajectory-Nov24/final_model.pth\nConcord - INFO - Final model saved at: ../save/dev_simulation_trajectory-Nov24/final_model.pth; Configuration saved at: ../save/dev_simulation_trajectory-Nov24/config.json.\nConcord.model.anndataset - INFO - Initialized dataset with 1000 samples. Data structure: ['input', 'domain', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[29]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Concord_UMAP']\n</pre> In\u00a0[32]: Copied! <pre>decoder_ccd = ccd.Concord(adata=adata, \n                      input_feature=None, \n                      batch_size=64,\n                      n_epochs=10,\n                      domain_key=batch_key, # key indicating batch\n                      class_key=leiden_key, # key indicating class\n                      use_classifier=False, # use classifier\n                      use_decoder=True,\n                      min_p_intra_domain=min_p_intra_domain, # probability of sampling intra-domain pairs\n                      domain_embedding_dim=8,\n                      seed=seed, # random seed\n                      verbose=False, # print training progress\n                      device=device, # device to run on\n                      save_dir=save_dir # directory to save model checkpoints\n                      ) \n\noutput_key = 'Concord-decoder'\nwith timer:\n    decoder_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)\n    \ntime_log[output_key] = timer.interval\n# Save the latent embedding to a file, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(decoder_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> decoder_ccd = ccd.Concord(adata=adata,                        input_feature=None,                        batch_size=64,                       n_epochs=10,                       domain_key=batch_key, # key indicating batch                       class_key=leiden_key, # key indicating class                       use_classifier=False, # use classifier                       use_decoder=True,                       min_p_intra_domain=min_p_intra_domain, # probability of sampling intra-domain pairs                       domain_embedding_dim=8,                       seed=seed, # random seed                       verbose=False, # print training progress                       device=device, # device to run on                       save_dir=save_dir # directory to save model checkpoints                       )   output_key = 'Concord-decoder' with timer:     decoder_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)      time_log[output_key] = timer.interval # Save the latent embedding to a file, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(decoder_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")  <pre>Concord - WARNING - No input feature list provided. It is recommended to first select features using the command `concord.ul.select_features()`.\n</pre> <pre>WARNING clustering 1000 points to 31 centroids: please provide at least 1209 training points\n</pre> <pre>p_intra_knn: 0.5\n</pre> <pre>Epoch 0 Training: 14it [00:00, 79.42it/s, loss=15.9]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 90.65it/s, loss=8.4]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 91.55it/s, loss=8.98]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 91.17it/s, loss=8.14]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 91.58it/s, loss=8.15]\nEpoch 5 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 76.94it/s, loss=7.27]\nEpoch 6 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 89.47it/s, loss=7.17]\nEpoch 7 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 68.10it/s, loss=7.57]\nEpoch 8 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 89.34it/s, loss=7.2]\nEpoch 9 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 92.33it/s, loss=7.09]\n</pre> In\u00a0[33]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) In\u00a0[24]: Copied! <pre># Predict and store the results\ndecoder_domains = adata.obs[batch_key].unique()\nfor domain in decoder_domains:\n    _, decoded, _, _, _, _ = decoder_ccd.predict(decoder_ccd.loader, return_decoded=True, decoder_domain=domain, return_class=True, return_class_prob=True)\n    save_key = f\"{output_key}_decoded_{domain}\"\n    adata.layers[save_key] = decoded\n\nadata.layers\n</pre> # Predict and store the results decoder_domains = adata.obs[batch_key].unique() for domain in decoder_domains:     _, decoded, _, _, _, _ = decoder_ccd.predict(decoder_ccd.loader, return_decoded=True, decoder_domain=domain, return_class=True, return_class_prob=True)     save_key = f\"{output_key}_decoded_{domain}\"     adata.layers[save_key] = decoded  adata.layers Out[24]: <pre>Layers with keys: Concord-decoder_decoded_batch_1, Concord-decoder_decoded_batch_2, Liger_corrected, Scanorama_corrected, counts, scANVI_corrected_batch_1, scVI_corrected_batch_1, wt_noise</pre> In\u00a0[30]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=None, \n                      batch_size=64,\n                      n_epochs=10,\n                      domain_key=batch_key, # key indicating batch\n                      class_key=leiden_key, # key indicating class\n                      use_classifier=True, # use classifier\n                      seed=seed, # random seed\n                      min_p_intra_domain=min_p_intra_domain, # probability of sampling intra-domain pairs\n                      verbose=False, # print training progress\n                      device=device, # device to run on\n                      save_dir=save_dir # directory to save model checkpoints\n                      ) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\noutput_key = 'Concord-class'\nwith timer:\n    cur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)\n    \ntime_log[output_key] = timer.interval\n# Save the latent embedding to a file, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=None,                        batch_size=64,                       n_epochs=10,                       domain_key=batch_key, # key indicating batch                       class_key=leiden_key, # key indicating class                       use_classifier=True, # use classifier                       seed=seed, # random seed                       min_p_intra_domain=min_p_intra_domain, # probability of sampling intra-domain pairs                       verbose=False, # print training progress                       device=device, # device to run on                       save_dir=save_dir # directory to save model checkpoints                       )   # Encode data, saving the latent embedding in adata.obsm['Concord'] output_key = 'Concord-class' with timer:     cur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)      time_log[output_key] = timer.interval # Save the latent embedding to a file, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Concord - WARNING - No input feature list provided. It is recommended to first select features using the command `concord.ul.select_features()`.\n</pre> <pre>WARNING clustering 1000 points to 31 centroids: please provide at least 1209 training points\n</pre> <pre>p_intra_knn: 0.5\n</pre> <pre>Epoch 0 Training: 14it [00:00, 86.72it/s, loss=7.16]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 89.68it/s, loss=6.15]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 88.57it/s, loss=5.99]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 89.72it/s, loss=5.53]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 92.24it/s, loss=5.49]\nEpoch 5 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 81.94it/s, loss=5.31]\nEpoch 6 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 92.42it/s, loss=5.32]\nEpoch 7 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 91.86it/s, loss=5.27]\nEpoch 8 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 92.45it/s, loss=5.04]\nEpoch 9 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 95.17it/s, loss=5.11]\n</pre> In\u00a0[31]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, result_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) In\u00a0[7]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=None, \n                      batch_size=64,\n                      n_epochs=10,\n                      domain_key=None, # key indicating batch\n                      seed=seed, # random seed\n                      verbose=True, # print training progress\n                      device=device, # device to run on\n                      save_dir=save_dir # directory to save model checkpoints\n                      ) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\noutput_key = 'Concord_nd'\ncur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=None,                        batch_size=64,                       n_epochs=10,                       domain_key=None, # key indicating batch                       seed=seed, # random seed                       verbose=True, # print training progress                       device=device, # device to run on                       save_dir=save_dir # directory to save model checkpoints                       )   # Encode data, saving the latent embedding in adata.obsm['Concord'] output_key = 'Concord_nd' cur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)  <pre>Concord - INFO - Setting sampler_knn to 20 to be 1/50 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - WARNING - No input feature list provided. It is recommended to first select features using the command `concord.ul.select_features()`.\nConcord - INFO - Proceeding with all 120 features in the dataset.\nConcord - WARNING - domain/batch information not found, all samples will be treated as from single domain/batch.\nConcord - INFO - Encoder input dim: 120\nConcord - INFO - Model loaded to device: cpu\nConcord - INFO - Total number of parameters: 19944\nConcord.model.anndataset - INFO - Initialized dataset with 1000 samples. Data structure: ['input', 'domain', 'idx']\nConcord.model.knn - INFO - Using euclidean distance metric.\nConcord.model.knn - WARNING - FAISS not found. Using sklearn for k-NN computation.\nConcord.model.dataloader - INFO - Number of unique_domains: 1\nConcord.model.dataloader - INFO - Final p_intra_domain values: single_domain: 1.00\n</pre> <pre>p_intra_knn: 0.3\nConcord - INFO - Starting epoch 1/10\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 0 Training: 15it [00:00, 46.13it/s, loss=4.08]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 4.23, MSE: 0.00, CLASS: 0.00, CONTRAST: 4.23, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 2/10\nConcord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00&lt;00:00, 214.74it/s, loss=3.91]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 3.93, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.93, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 3/10\nConcord - INFO - Processing chunk 1/1 for epoch 3\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00&lt;00:00, 298.30it/s, loss=3.76]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 3.84, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.84, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 4/10\nConcord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00&lt;00:00, 221.84it/s, loss=3.75]</pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 3.76, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.76, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 5/10\nConcord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00&lt;00:00, 293.11it/s, loss=3.67]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 3.71, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.71, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 6/10\nConcord - INFO - Processing chunk 1/1 for epoch 6\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 5 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00&lt;00:00, 216.63it/s, loss=3.65]</pre> <pre>Concord - INFO - Epoch   5 | Train Loss: 3.67, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.67, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 7/10\nConcord - INFO - Processing chunk 1/1 for epoch 7\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>\nEpoch 6 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00&lt;00:00, 237.05it/s, loss=3.67]</pre> <pre>Concord - INFO - Epoch   6 | Train Loss: 3.65, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.65, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 8/10\nConcord - INFO - Processing chunk 1/1 for epoch 8\n</pre> <pre>\n</pre> <pre>Concord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 7 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00&lt;00:00, 209.42it/s, loss=3.74]</pre> <pre>Concord - INFO - Epoch   7 | Train Loss: 3.68, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.68, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 9/10\nConcord - INFO - Processing chunk 1/1 for epoch 9\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 8 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00&lt;00:00, 300.22it/s, loss=3.59]</pre> <pre>Concord - INFO - Epoch   8 | Train Loss: 3.66, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.66, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 10/10\nConcord - INFO - Processing chunk 1/1 for epoch 10\nConcord - INFO - Number of samples in train_dataloader: 1000\n</pre> <pre>Epoch 9 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00&lt;00:00, 210.86it/s, loss=3.63]</pre> <pre>Concord - INFO - Epoch   9 | Train Loss: 3.64, MSE: 0.00, CLASS: 0.00, CONTRAST: 3.64, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Model saved to ../save/dev_simulation_trajectory-Feb16/final_model_Feb16-1615.pt\nConcord - INFO - Final model saved at: ../save/dev_simulation_trajectory-Feb16/final_model_Feb16-1615.pt; Configuration saved at: ../save/dev_simulation_trajectory-Feb16/config_Feb16-1615.json.\nConcord.model.anndataset - INFO - Initialized dataset with 1000 samples. Data structure: ['input', 'domain', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[8]: Copied! <pre>adata.obsm['Unintegrated'] = adata.obsm['X_pca']\nn_pc=30\nccd.ul.run_pca(adata_state, source_key='no_noise', result_key='PCA_no_noise', n_pc=n_pc, random_state=seed)\nccd.ul.run_pca(adata_state, source_key='wt_noise', result_key='PCA_wt_noise', n_pc=n_pc, random_state=seed)\n\n# Put the PCA result in the adata object, so only one object is needed\nadata.obsm['PCA_no_noise'] = adata_state.obsm['PCA_no_noise']\nadata.obsm['PCA_wt_noise'] = adata_state.obsm['PCA_wt_noise']\nadata.obsm\n</pre> adata.obsm['Unintegrated'] = adata.obsm['X_pca'] n_pc=30 ccd.ul.run_pca(adata_state, source_key='no_noise', result_key='PCA_no_noise', n_pc=n_pc, random_state=seed) ccd.ul.run_pca(adata_state, source_key='wt_noise', result_key='PCA_wt_noise', n_pc=n_pc, random_state=seed)  # Put the PCA result in the adata object, so only one object is needed adata.obsm['PCA_no_noise'] = adata_state.obsm['PCA_no_noise'] adata.obsm['PCA_wt_noise'] = adata_state.obsm['PCA_wt_noise'] adata.obsm <pre>Concord - INFO - PCA performed on source data with 30 components\nConcord - INFO - PCA embedding stored in adata.obsm['PCA_no_noise']\nConcord - INFO - PCA performed on source data with 30 components\nConcord - INFO - PCA embedding stored in adata.obsm['PCA_wt_noise']\n</pre> Out[8]: <pre>AxisArrays with keys: Concord, Concord-class, Concord-class_PCA, Concord-class_UMAP, Concord-decoder, Concord-decoder_PCA, Concord-decoder_UMAP, Concord_PCA, Concord_UMAP, Concord_UMAP_2D, Harmony, Harmony_PCA, Harmony_UMAP, Liger, Liger_PCA, Liger_UMAP, PCA_no_noise, PCA_no_noise_UMAP, PCA_wt_noise, PCA_wt_noise_UMAP, Scanorama, Scanorama_PCA, Scanorama_UMAP, Unintegrated, Unintegrated_PCA, Unintegrated_UMAP, X_pca, X_umap, scANVI, scANVI_PCA, scANVI_UMAP, scVI, scVI_PCA, scVI_UMAP, Concord_nd</pre> In\u00a0[9]: Copied! <pre>latent_keys = [\"Unintegrated\", \"Scanorama\", \"Liger\", \"Harmony\", \"scVI\",\"Concord_nd\", \"Concord\", 'Concord-decoder', \"Concord-class\",  \"scANVI\"]\nground_keys = ['PCA_no_noise', 'PCA_wt_noise']\ncombined_keys = ground_keys + latent_keys \n</pre> latent_keys = [\"Unintegrated\", \"Scanorama\", \"Liger\", \"Harmony\", \"scVI\",\"Concord_nd\", \"Concord\", 'Concord-decoder', \"Concord-class\",  \"scANVI\"] ground_keys = ['PCA_no_noise', 'PCA_wt_noise'] combined_keys = ground_keys + latent_keys   In\u00a0[13]: Copied! <pre># Run umap and PCA for all latent embeddings\nfor basis in combined_keys:\n    print(\"Running UMAP and PCA for\", basis)\n    if basis not in adata.obsm:\n        continue\n    #if 'UMAP' not in basis:\n    ccd.ul.run_umap(adata, source_key=basis, result_key=f'{basis}_UMAP', n_components=2, n_neighbors=30, min_dist=0.8, metric='euclidean', random_state=seed)\n    if 'PCA' not in basis:\n        n_pc = min(adata.obsm[basis].shape[1], adata.shape[0]) - 1\n        ccd.ul.run_pca(adata, source_key=basis, result_key=f'{basis}_PCA', n_pc=n_pc, random_state=seed)\n</pre>   # Run umap and PCA for all latent embeddings for basis in combined_keys:     print(\"Running UMAP and PCA for\", basis)     if basis not in adata.obsm:         continue     #if 'UMAP' not in basis:     ccd.ul.run_umap(adata, source_key=basis, result_key=f'{basis}_UMAP', n_components=2, n_neighbors=30, min_dist=0.8, metric='euclidean', random_state=seed)     if 'PCA' not in basis:         n_pc = min(adata.obsm[basis].shape[1], adata.shape[0]) - 1         ccd.ul.run_pca(adata, source_key=basis, result_key=f'{basis}_PCA', n_pc=n_pc, random_state=seed)  <pre>Running UMAP and PCA for PCA_no_noise\nConcord - INFO - UMAP embedding stored in adata.obsm['PCA_no_noise_UMAP']\nRunning UMAP and PCA for PCA_wt_noise\nConcord - INFO - UMAP embedding stored in adata.obsm['PCA_wt_noise_UMAP']\nRunning UMAP and PCA for Unintegrated\nConcord - INFO - UMAP embedding stored in adata.obsm['Unintegrated_UMAP']\nConcord - INFO - PCA performed on source data with 49 components\nConcord - INFO - PCA embedding stored in adata.obsm['Unintegrated_PCA']\nRunning UMAP and PCA for Scanorama\nConcord - INFO - UMAP embedding stored in adata.obsm['Scanorama_UMAP']\nConcord - INFO - PCA performed on source data with 99 components\nConcord - INFO - PCA embedding stored in adata.obsm['Scanorama_PCA']\nRunning UMAP and PCA for Liger\nConcord - INFO - UMAP embedding stored in adata.obsm['Liger_UMAP']\nConcord - INFO - PCA performed on source data with 29 components\nConcord - INFO - PCA embedding stored in adata.obsm['Liger_PCA']\nRunning UMAP and PCA for Harmony\nConcord - INFO - UMAP embedding stored in adata.obsm['Harmony_UMAP']\nConcord - INFO - PCA performed on source data with 118 components\nConcord - INFO - PCA embedding stored in adata.obsm['Harmony_PCA']\nRunning UMAP and PCA for scVI\nConcord - INFO - UMAP embedding stored in adata.obsm['scVI_UMAP']\nConcord - INFO - PCA performed on source data with 29 components\nConcord - INFO - PCA embedding stored in adata.obsm['scVI_PCA']\nRunning UMAP and PCA for Concord_nd\nConcord - INFO - UMAP embedding stored in adata.obsm['Concord_nd_UMAP']\nConcord - INFO - PCA performed on source data with 31 components\nConcord - INFO - PCA embedding stored in adata.obsm['Concord_nd_PCA']\nRunning UMAP and PCA for Concord\nConcord - INFO - UMAP embedding stored in adata.obsm['Concord_UMAP']\nConcord - INFO - PCA performed on source data with 31 components\nConcord - INFO - PCA embedding stored in adata.obsm['Concord_PCA']\nRunning UMAP and PCA for Concord-decoder\nConcord - INFO - UMAP embedding stored in adata.obsm['Concord-decoder_UMAP']\nConcord - INFO - PCA performed on source data with 31 components\nConcord - INFO - PCA embedding stored in adata.obsm['Concord-decoder_PCA']\nRunning UMAP and PCA for Concord-class\nConcord - INFO - UMAP embedding stored in adata.obsm['Concord-class_UMAP']\nConcord - INFO - PCA performed on source data with 31 components\nConcord - INFO - PCA embedding stored in adata.obsm['Concord-class_PCA']\nRunning UMAP and PCA for scANVI\nConcord - INFO - UMAP embedding stored in adata.obsm['scANVI_UMAP']\nConcord - INFO - PCA performed on source data with 29 components\nConcord - INFO - PCA embedding stored in adata.obsm['scANVI_PCA']\n</pre> In\u00a0[12]: Copied! <pre>adata.write_h5ad(data_dir / f\"adata_{file_suffix}.h5ad\")\nadata_state.write_h5ad(data_dir / f\"adata_state_{file_suffix}.h5ad\")\nfile_suffix\n</pre> adata.write_h5ad(data_dir / f\"adata_{file_suffix}.h5ad\") adata_state.write_h5ad(data_dir / f\"adata_state_{file_suffix}.h5ad\") file_suffix Out[12]: <pre>'Feb07-1613'</pre> In\u00a0[15]: Copied! <pre>adata.obsm\n</pre> adata.obsm Out[15]: <pre>AxisArrays with keys: Concord, Concord-class, Concord-class_PCA, Concord-class_UMAP, Concord-decoder, Concord-decoder_PCA, Concord-decoder_UMAP, Concord_PCA, Concord_UMAP, Concord_UMAP_2D, Harmony, Harmony_PCA, Harmony_UMAP, Liger, Liger_PCA, Liger_UMAP, PCA_no_noise, PCA_no_noise_UMAP, PCA_wt_noise, PCA_wt_noise_UMAP, Scanorama, Scanorama_PCA, Scanorama_UMAP, Unintegrated, Unintegrated_PCA, Unintegrated_UMAP, X_pca, X_umap, scANVI, scANVI_PCA, scANVI_UMAP, scVI, scVI_PCA, scVI_UMAP, Concord_nd, Concord_nd_UMAP, Concord_nd_PCA, X_draw_graph_kk</pre> In\u00a0[14]: Copied! <pre># plot everything\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\n# from matplotlib import font_manager, rcParams\n\n# # Add custom font path\n# font_dirs = ['/wynton/home/gartner/zhuqin/.conda/envs/cellpath/fonts']  # Your custom fonts directory\n# font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n\n# # Create FontProperties for each custom font and add to the font manager\n# for font_path in font_files:\n#     font_manager.fontManager.addfont(font_path)\n\n# Set Arial as the default font\ncustom_rc = {\n    'font.family': 'Arial',  # Set the desired font for this plot\n}\n\ncolor_bys = ['time', 'batch']\nbasis_types = ['KNN', 'UMAP']\n#basis_types = ['PCA']\nfont_size=8\npoint_size=2.5\nalpha=0.8\nfigsize=(0.9*len(combined_keys),1)\nncols = len(combined_keys)\nnrows = int(np.ceil(len(combined_keys) / ncols))\npal = {'time':'viridis', 'batch':'Set1'}\nk=15\nedges_color='grey'\nedges_width=0\nlayout='kk'\nthreshold = 0.1\nnode_size_scale=0.1\nedge_width_scale=0.1\n\nrasterized = True\nwith plt.rc_context(rc=custom_rc):\n    ccd.pl.plot_all_embeddings(\n        adata,\n        combined_keys,\n        color_bys=color_bys,\n        basis_types=basis_types,\n        pal=pal,\n        k=k,\n        edges_color=edges_color,\n        edges_width=edges_width,\n        layout=layout,\n        threshold=threshold,\n        node_size_scale=node_size_scale,\n        edge_width_scale=edge_width_scale,\n        font_size=font_size,\n        point_size=point_size,\n        alpha=alpha,\n        rasterized=rasterized,\n        figsize=figsize,\n        ncols=ncols,\n        seed=seed,\n        leiden_key='leiden',\n        save_dir=save_dir,\n        file_suffix=file_suffix+f'rasterized_{rasterized}',\n        save_format='svg'\n    )\n</pre> # plot everything import matplotlib.pyplot as plt import pandas as pd   # from matplotlib import font_manager, rcParams  # # Add custom font path # font_dirs = ['/wynton/home/gartner/zhuqin/.conda/envs/cellpath/fonts']  # Your custom fonts directory # font_files = font_manager.findSystemFonts(fontpaths=font_dirs)  # # Create FontProperties for each custom font and add to the font manager # for font_path in font_files: #     font_manager.fontManager.addfont(font_path)  # Set Arial as the default font custom_rc = {     'font.family': 'Arial',  # Set the desired font for this plot }  color_bys = ['time', 'batch'] basis_types = ['KNN', 'UMAP'] #basis_types = ['PCA'] font_size=8 point_size=2.5 alpha=0.8 figsize=(0.9*len(combined_keys),1) ncols = len(combined_keys) nrows = int(np.ceil(len(combined_keys) / ncols)) pal = {'time':'viridis', 'batch':'Set1'} k=15 edges_color='grey' edges_width=0 layout='kk' threshold = 0.1 node_size_scale=0.1 edge_width_scale=0.1  rasterized = True with plt.rc_context(rc=custom_rc):     ccd.pl.plot_all_embeddings(         adata,         combined_keys,         color_bys=color_bys,         basis_types=basis_types,         pal=pal,         k=k,         edges_color=edges_color,         edges_width=edges_width,         layout=layout,         threshold=threshold,         node_size_scale=node_size_scale,         edge_width_scale=edge_width_scale,         font_size=font_size,         point_size=point_size,         alpha=alpha,         rasterized=rasterized,         figsize=figsize,         ncols=ncols,         seed=seed,         leiden_key='leiden',         save_dir=save_dir,         file_suffix=file_suffix+f'rasterized_{rasterized}',         save_format='svg'     )  <pre>Concord.plotting.pl_embedding - INFO - Plotting PCA_no_noise with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting PCA_wt_noise with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Unintegrated with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Scanorama with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Liger with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Harmony with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting scVI with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Concord_nd with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Concord with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Concord-decoder with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Concord-class with time in KNN\nConcord.plotting.pl_embedding - INFO - Plotting scANVI with time in KNN\n</pre> <pre>Concord.plotting.pl_embedding - INFO - Plotting PCA_no_noise with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting PCA_wt_noise with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Unintegrated with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Scanorama with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Liger with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Harmony with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting scVI with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Concord_nd with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Concord with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Concord-decoder with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting Concord-class with batch in KNN\nConcord.plotting.pl_embedding - INFO - Plotting scANVI with batch in KNN\n</pre> <pre>Concord.plotting.pl_embedding - INFO - Plotting PCA_no_noise with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting PCA_wt_noise with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Unintegrated with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Scanorama with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Liger with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Harmony with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting scVI with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Concord_nd with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Concord with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Concord-decoder with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Concord-class with time in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting scANVI with time in UMAP\n</pre> <pre>Concord.plotting.pl_embedding - INFO - Plotting PCA_no_noise with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting PCA_wt_noise with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Unintegrated with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Scanorama with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Liger with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Harmony with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting scVI with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Concord_nd with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Concord with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Concord-decoder with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting Concord-class with batch in UMAP\nConcord.plotting.pl_embedding - INFO - Plotting scANVI with batch in UMAP\n</pre> In\u00a0[200]: Copied! <pre>adata.layers['no_noise'] = np.zeros_like(adata.X)\nadata.layers['wt_noise'] = np.zeros_like(adata.X)\n# Find the indices of common genes between `adata` and `adata_state`\ncommon_genes = adata.var_names.intersection(adata_state.var_names)\nadata_indices = adata.var_names.get_indexer(common_genes)\nadata_state_indices = adata_state.var_names.get_indexer(common_genes)\n\n# Copy data from `adata_state` to `adata` for these common genes\nadata.layers['no_noise'][:, adata_indices] = adata_state.layers['no_noise'][:, adata_state_indices].copy()\nadata.layers['wt_noise'][:, adata_indices] = adata_state.layers['wt_noise'][:, adata_state_indices].copy()\n\n# sort and smooth the signal along the path\nbatch_id=adata.obs['batch'].unique()[0]\nbatch_indices = np.where(adata.obs['batch'] == batch_id)[0]\n_, _, _, feature_order = ccd.ul.sort_and_smooth_signal_along_path(adata, signal_key='Concord', path=batch_indices, sigma=2)\nadata.obsm['Concord_sorted'] = adata.obsm['Concord'][:, feature_order]\n\n_, _, _, feature_order = ccd.ul.sort_and_smooth_signal_along_path(adata, signal_key='Concord-decoder', path=batch_indices, sigma=2)\nadata.obsm['Concord-decoder_sorted'] = adata.obsm['Concord-decoder'][:, feature_order]\n</pre> adata.layers['no_noise'] = np.zeros_like(adata.X) adata.layers['wt_noise'] = np.zeros_like(adata.X) # Find the indices of common genes between `adata` and `adata_state` common_genes = adata.var_names.intersection(adata_state.var_names) adata_indices = adata.var_names.get_indexer(common_genes) adata_state_indices = adata_state.var_names.get_indexer(common_genes)  # Copy data from `adata_state` to `adata` for these common genes adata.layers['no_noise'][:, adata_indices] = adata_state.layers['no_noise'][:, adata_state_indices].copy() adata.layers['wt_noise'][:, adata_indices] = adata_state.layers['wt_noise'][:, adata_state_indices].copy()  # sort and smooth the signal along the path batch_id=adata.obs['batch'].unique()[0] batch_indices = np.where(adata.obs['batch'] == batch_id)[0] _, _, _, feature_order = ccd.ul.sort_and_smooth_signal_along_path(adata, signal_key='Concord', path=batch_indices, sigma=2) adata.obsm['Concord_sorted'] = adata.obsm['Concord'][:, feature_order]  _, _, _, feature_order = ccd.ul.sort_and_smooth_signal_along_path(adata, signal_key='Concord-decoder', path=batch_indices, sigma=2) adata.obsm['Concord-decoder_sorted'] = adata.obsm['Concord-decoder'][:, feature_order] In\u00a0[42]: Copied! <pre># Plot heatmap of original data and Concord latent\nimport matplotlib.pyplot as plt\nfigsize = (2.3, 1.8)\nncols = 5\ntitle_fontsize = 9\ndpi = 600\nfig, axes = plt.subplots(1, ncols, figsize=(figsize[0] * ncols, figsize[1]), dpi=dpi)\nccd.pl.heatmap_with_annotations(adata, val='no_noise', obs_keys=[state_key], ax = axes[0], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='State', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\nccd.pl.heatmap_with_annotations(adata, val='wt_noise', obs_keys=[state_key], ax = axes[1], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='State+noise', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\nccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key], ax = axes[2], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='State+noise+batch', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\nccd.pl.heatmap_with_annotations(adata, val='Concord_sorted', obs_keys=[state_key, batch_key], ax = axes[3], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Concord latent', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\nccd.pl.heatmap_with_annotations(adata, val='Concord-decoder_sorted', obs_keys=[state_key, batch_key], ax = axes[4], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Concord-decoder latent', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\nplt.tight_layout(w_pad=0.0, h_pad=0.1)\nplt.savefig(save_dir / f\"all_heatmaps_{file_suffix}.svg\", dpi=dpi, bbox_inches='tight')\n</pre> # Plot heatmap of original data and Concord latent import matplotlib.pyplot as plt figsize = (2.3, 1.8) ncols = 5 title_fontsize = 9 dpi = 600 fig, axes = plt.subplots(1, ncols, figsize=(figsize[0] * ncols, figsize[1]), dpi=dpi) ccd.pl.heatmap_with_annotations(adata, val='no_noise', obs_keys=[state_key], ax = axes[0], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='State', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize) ccd.pl.heatmap_with_annotations(adata, val='wt_noise', obs_keys=[state_key], ax = axes[1], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='State+noise', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize) ccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key], ax = axes[2], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='State+noise+batch', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize) ccd.pl.heatmap_with_annotations(adata, val='Concord_sorted', obs_keys=[state_key, batch_key], ax = axes[3], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Concord latent', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize) ccd.pl.heatmap_with_annotations(adata, val='Concord-decoder_sorted', obs_keys=[state_key, batch_key], ax = axes[4], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Concord-decoder latent', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize) plt.tight_layout(w_pad=0.0, h_pad=0.1) plt.savefig(save_dir / f\"all_heatmaps_{file_suffix}.svg\", dpi=dpi, bbox_inches='tight') In\u00a0[5]: Copied! <pre>adata = sc.read(data_dir / f\"adata_Nov24-2032.h5ad\")\nadata_state = sc.read(data_dir / f\"adata_state_Nov24-2032.h5ad\")\n</pre> adata = sc.read(data_dir / f\"adata_Nov24-2032.h5ad\") adata_state = sc.read(data_dir / f\"adata_state_Nov24-2032.h5ad\") In\u00a0[\u00a0]: Copied! <pre>from scipy.sparse.csgraph import minimum_spanning_tree\nknn_graph = adata_b1.obsp['connectivities']\n# Compute the minimum spanning tree\nmst_sparse = minimum_spanning_tree(knn_graph)\n\n# Convert the MST to a sparse COO matrix (easier to work with)\nmst_coo = mst_sparse.tocoo()\n\n# Extract edges from the MST\nmst_coo = mst_sparse.tocoo()  # Convert MST to COO format for easier processing\n\n# Get the coordinates of nodes (cells) in the embedding\nembedding = adata_b1.obsm[show_basis]  # Use UMAP embedding (or PCA, etc.)\n\n# Extract the coordinates of the edges\nedges_x = []\nedges_y = []\n\nfor i, j in zip(mst_coo.row, mst_coo.col):\n    edges_x.append([embedding[i, 0], embedding[j, 0]])  # x-coordinates of the edge\n    edges_y.append([embedding[i, 1], embedding[j, 1]])  # y-coordinates of the edge\n\nimport matplotlib.pyplot as plt\n\n# Scatter plot of the embedding\nplt.figure(figsize=(10, 8))\nplt.scatter(embedding[:, 0], embedding[:, 1], s=10, c=adata_b1.obs[\"time\"], cmap=\"viridis\")\n\n# Plot the edges of the MST\nfor x, y in zip(edges_x, edges_y):\n    plt.plot(x, y, color=\"black\", linewidth=0.1)  # Draw edges\n\n# Add labels and legend\nplt.title(\"Minimum Spanning Tree on UMAP Embedding\")\nplt.xlabel(\"UMAP 1\")\nplt.ylabel(\"UMAP 2\")\nplt.colorbar(label=\"Pseudotime\")\nplt.legend()\nplt.show()\n\nfrom scipy.sparse.csgraph import dijkstra\nroot_node=0\n# Compute shortest path lengths from the root node\ndistances, predecessors = dijkstra(mst_sparse, directed=False, return_predecessors=True, indices=root_node)\n# Assign pseudotime directly to nodes\npseudotime = distances\n\n# Project pseudotime onto all cells\ncell_pseudotime = np.zeros(adata_b1.n_obs)\n\n# Iterate over all cells\nfor i, cell in enumerate(adata_b1.obsm[show_basis]):\n    min_dist = float(\"inf\")\n    assigned_time = 0\n    for start, end, weight in zip(mst_coo.row, mst_coo.col, mst_coo.data):\n        # Get coordinates of the two nodes defining the edge\n        coord_start, coord_end = adata_b1.obsm[show_basis][start], adata_b1.obsm[show_basis][end]\n        \n        # Project cell onto the edge\n        edge_vector = coord_end - coord_start\n        cell_vector = cell - coord_start\n        proj_length = np.dot(cell_vector, edge_vector) / np.dot(edge_vector, edge_vector)\n        proj_length = np.clip(proj_length, 0, 1)  # Clip to edge bounds\n        proj_point = coord_start + proj_length * edge_vector\n        dist = np.linalg.norm(cell - proj_point)\n        \n        # Assign pseudotime based on projection\n        if dist &lt; min_dist:\n            min_dist = dist\n            assigned_time = (1 - proj_length) * pseudotime[start] + proj_length * pseudotime[end]\n    \n    cell_pseudotime[i] = assigned_time\n\n# Normalize pseudotime to 0-1\ncell_pseudotime = (cell_pseudotime - cell_pseudotime.min()) / (cell_pseudotime.max() - cell_pseudotime.min())\n\n# Add to AnnData\nadata_b1.obs[\"pseudotime_mst\"] = cell_pseudotime\n</pre> from scipy.sparse.csgraph import minimum_spanning_tree knn_graph = adata_b1.obsp['connectivities'] # Compute the minimum spanning tree mst_sparse = minimum_spanning_tree(knn_graph)  # Convert the MST to a sparse COO matrix (easier to work with) mst_coo = mst_sparse.tocoo()  # Extract edges from the MST mst_coo = mst_sparse.tocoo()  # Convert MST to COO format for easier processing  # Get the coordinates of nodes (cells) in the embedding embedding = adata_b1.obsm[show_basis]  # Use UMAP embedding (or PCA, etc.)  # Extract the coordinates of the edges edges_x = [] edges_y = []  for i, j in zip(mst_coo.row, mst_coo.col):     edges_x.append([embedding[i, 0], embedding[j, 0]])  # x-coordinates of the edge     edges_y.append([embedding[i, 1], embedding[j, 1]])  # y-coordinates of the edge  import matplotlib.pyplot as plt  # Scatter plot of the embedding plt.figure(figsize=(10, 8)) plt.scatter(embedding[:, 0], embedding[:, 1], s=10, c=adata_b1.obs[\"time\"], cmap=\"viridis\")  # Plot the edges of the MST for x, y in zip(edges_x, edges_y):     plt.plot(x, y, color=\"black\", linewidth=0.1)  # Draw edges  # Add labels and legend plt.title(\"Minimum Spanning Tree on UMAP Embedding\") plt.xlabel(\"UMAP 1\") plt.ylabel(\"UMAP 2\") plt.colorbar(label=\"Pseudotime\") plt.legend() plt.show()  from scipy.sparse.csgraph import dijkstra root_node=0 # Compute shortest path lengths from the root node distances, predecessors = dijkstra(mst_sparse, directed=False, return_predecessors=True, indices=root_node) # Assign pseudotime directly to nodes pseudotime = distances  # Project pseudotime onto all cells cell_pseudotime = np.zeros(adata_b1.n_obs)  # Iterate over all cells for i, cell in enumerate(adata_b1.obsm[show_basis]):     min_dist = float(\"inf\")     assigned_time = 0     for start, end, weight in zip(mst_coo.row, mst_coo.col, mst_coo.data):         # Get coordinates of the two nodes defining the edge         coord_start, coord_end = adata_b1.obsm[show_basis][start], adata_b1.obsm[show_basis][end]                  # Project cell onto the edge         edge_vector = coord_end - coord_start         cell_vector = cell - coord_start         proj_length = np.dot(cell_vector, edge_vector) / np.dot(edge_vector, edge_vector)         proj_length = np.clip(proj_length, 0, 1)  # Clip to edge bounds         proj_point = coord_start + proj_length * edge_vector         dist = np.linalg.norm(cell - proj_point)                  # Assign pseudotime based on projection         if dist &lt; min_dist:             min_dist = dist             assigned_time = (1 - proj_length) * pseudotime[start] + proj_length * pseudotime[end]          cell_pseudotime[i] = assigned_time  # Normalize pseudotime to 0-1 cell_pseudotime = (cell_pseudotime - cell_pseudotime.min()) / (cell_pseudotime.max() - cell_pseudotime.min())  # Add to AnnData adata_b1.obs[\"pseudotime_mst\"] = cell_pseudotime  In\u00a0[1]: Copied! <pre>from scib_metrics.benchmark import Benchmarker\nbm = Benchmarker(\n    adata,\n    batch_key=batch_key,\n    label_key=leiden_key,\n    embedding_obsm_keys=latent_keys,\n    n_jobs=6,\n)\nbm.benchmark()\n</pre> from scib_metrics.benchmark import Benchmarker bm = Benchmarker(     adata,     batch_key=batch_key,     label_key=leiden_key,     embedding_obsm_keys=latent_keys,     n_jobs=6, ) bm.benchmark() <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[1], line 1\n----&gt; 1 from scib_metrics.benchmark import Benchmarker\n      2 bm = Benchmarker(\n      3     adata,\n      4     batch_key=batch_key,\n   (...)\n      7     n_jobs=6,\n      8 )\n      9 bm.benchmark()\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/scib_metrics/__init__.py:4\n      1 import logging\n      2 from importlib.metadata import version\n----&gt; 4 from . import nearest_neighbors, utils\n      5 from ._graph_connectivity import graph_connectivity\n      6 from ._isolated_labels import isolated_labels\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/scib_metrics/nearest_neighbors/__init__.py:1\n----&gt; 1 from ._dataclass import NeighborsResults\n      2 from ._jax import jax_approx_min_k\n      3 from ._pynndescent import pynndescent\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/scib_metrics/nearest_neighbors/_dataclass.py:7\n      5 import numpy as np\n      6 from scipy.sparse import coo_matrix, csr_matrix\n----&gt; 7 from umap.umap_ import fuzzy_simplicial_set\n     10 @dataclass\n     11 class NeighborsResults:\n     12     \"\"\"Nearest neighbors results data store.\n     13 \n     14     Attributes\n   (...)\n     21         the self edge.\n     22     \"\"\"\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/umap/__init__.py:2\n      1 from warnings import warn, catch_warnings, simplefilter\n----&gt; 2 from .umap_ import UMAP\n      4 try:\n      5     with catch_warnings():\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/umap/umap_.py:29\n     27 from scipy.sparse import tril as sparse_tril, triu as sparse_triu\n     28 import scipy.sparse.csgraph\n---&gt; 29 import numba\n     31 import umap.distances as dist\n     33 import umap.sparse as sparse\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/numba/__init__.py:77\n     74 from numba.core import types, errors\n     76 # Re-export typeof\n---&gt; 77 from numba.misc.special import (\n     78     typeof, prange, pndindex, gdb, gdb_breakpoint, gdb_init,\n     79     literally, literal_unroll,\n     80 )\n     82 # Re-export error classes\n     83 from numba.core.errors import *\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/numba/misc/special.py:3\n      1 import numpy as np\n----&gt; 3 from numba.core.typing.typeof import typeof\n      4 from numba.core.typing.asnumbatype import as_numba_type\n      7 def pndindex(*args):\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/numba/core/typing/__init__.py:1\n----&gt; 1 from .context import BaseContext, Context\n      2 from .templates import (signature, make_concrete_template, Signature,\n      3                         fold_arguments)\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/numba/core/typing/context.py:14\n     12 from numba.core.typing import templates\n     13 from numba.core.utils import order_by_target_specificity\n---&gt; 14 from .typeof import typeof, Purpose\n     16 from numba.core import utils\n     19 class Rating(object):\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/numba/core/typing/typeof.py:10\n      7 from numpy.random.bit_generator import BitGenerator\n      9 from numba.core import types, utils, errors\n---&gt; 10 from numba.np import numpy_support\n     13 # terminal color markup\n     14 _termcolor = errors.termcolor()\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/numba/np/numpy_support.py:13\n     10 from numba.core.errors import TypingError\n     12 # re-export\n---&gt; 13 from numba.core.cgutils import is_nonelike   # noqa: F401\n     16 numpy_version = tuple(map(int, np.__version__.split('.')[:2]))\n     19 FROM_DTYPE = {\n     20     np.dtype('bool'): types.boolean,\n     21     np.dtype('int8'): types.int8,\n   (...)\n     37     np.dtype(object): types.pyobject,\n     38 }\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/numba/core/cgutils.py:12\n      8 import functools\n     10 from llvmlite import ir\n---&gt; 12 from numba.core import utils, types, config, debuginfo\n     13 import numba.core.datamodel\n     16 bool_t = ir.IntType(1)\n\nFile ~/.conda/envs/cellpath/lib/python3.9/site-packages/numba/core/debuginfo.py:12\n     10 from llvmlite import ir\n     11 from numba.core import cgutils, types\n---&gt; 12 from numba.core.datamodel.models import ComplexModel, UniTupleModel\n     13 from numba.core import config\n     16 @contextmanager\n     17 def suspend_emission(builder):\n\nFile &lt;frozen importlib._bootstrap&gt;:1007, in _find_and_load(name, import_)\n\nFile &lt;frozen importlib._bootstrap&gt;:986, in _find_and_load_unlocked(name, import_)\n\nFile &lt;frozen importlib._bootstrap&gt;:680, in _load_unlocked(spec)\n\nFile &lt;frozen importlib._bootstrap_external&gt;:846, in exec_module(self, module)\n\nFile &lt;frozen importlib._bootstrap_external&gt;:941, in get_code(self, fullname)\n\nFile &lt;frozen importlib._bootstrap_external&gt;:1040, in get_data(self, path)\n\nKeyboardInterrupt: </pre> In\u00a0[44]: Copied! <pre>import matplotlib.pyplot as plt\nimport os\nbm.plot_results_table(min_max_scale=False, show=False)\nfig = plt.gcf()\nfig.set_size_inches(15, 6) \nfig.savefig(os.path.join(save_dir, f'scibmetrics_results_{file_suffix}.pdf'), facecolor='white', dpi=600)\nplt.show()\nplt.close(fig)\n</pre> import matplotlib.pyplot as plt import os bm.plot_results_table(min_max_scale=False, show=False) fig = plt.gcf() fig.set_size_inches(15, 6)  fig.savefig(os.path.join(save_dir, f'scibmetrics_results_{file_suffix}.pdf'), facecolor='white', dpi=600) plt.show() plt.close(fig) In\u00a0[45]: Copied! <pre>scib_scores = bm.get_results(min_max_scale=False)\n# Convert row 'Metric Type' to multi-index column, first level is 'Metric Type', second level is existing column name\nmetric_type = scib_scores.loc['Metric Type']\nscib_scores = scib_scores.drop('Metric Type')  # Drop the last row now that it's stored in metric_type\nscib_scores.columns = pd.MultiIndex.from_tuples([(metric_type[col], col) for col in scib_scores.columns])\nscib_scores = ccd.ul.benchmark_stats_to_score(scib_scores, min_max_scale=False, one_minus=False, aggregate_score=False, rank=True, rank_col=('Aggregate score', 'Total'), name_exact=False)\n\nccd.pl.plot_benchmark_table(scib_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', save_path=save_dir / f\"scib_results_{file_suffix}.pdf\", figsize=(16, 6), dpi=300)\n</pre> scib_scores = bm.get_results(min_max_scale=False) # Convert row 'Metric Type' to multi-index column, first level is 'Metric Type', second level is existing column name metric_type = scib_scores.loc['Metric Type'] scib_scores = scib_scores.drop('Metric Type')  # Drop the last row now that it's stored in metric_type scib_scores.columns = pd.MultiIndex.from_tuples([(metric_type[col], col) for col in scib_scores.columns]) scib_scores = ccd.ul.benchmark_stats_to_score(scib_scores, min_max_scale=False, one_minus=False, aggregate_score=False, rank=True, rank_col=('Aggregate score', 'Total'), name_exact=False)  ccd.pl.plot_benchmark_table(scib_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', save_path=save_dir / f\"scib_results_{file_suffix}.pdf\", figsize=(16, 6), dpi=300) <p>Run topological analysis pipeline:</p> In\u00a0[47]: Copied! <pre>homology_dimensions = [0,1,2]\nconcord_keys = ['Concord', 'Concord-decoder', 'Concord-class']\n#diagrams = {}\n#for key in combined_keys:\nfor key in concord_keys:\n    print(f\"Computing persistent homology for {key}\")\n    diagrams[key] =  ccd.ul.compute_persistent_homology(adata, key=key, homology_dimensions=homology_dimensions)\n\nimport pickle\nwith open(save_dir / f\"topology_diagrams_{file_suffix}.pkl\", 'wb') as f:\n    pickle.dump(diagrams, f)\n</pre> homology_dimensions = [0,1,2] concord_keys = ['Concord', 'Concord-decoder', 'Concord-class'] #diagrams = {} #for key in combined_keys: for key in concord_keys:     print(f\"Computing persistent homology for {key}\")     diagrams[key] =  ccd.ul.compute_persistent_homology(adata, key=key, homology_dimensions=homology_dimensions)  import pickle with open(save_dir / f\"topology_diagrams_{file_suffix}.pkl\", 'wb') as f:     pickle.dump(diagrams, f) <pre>Computing persistent homology for Concord\nComputing persistent homology for Concord-decoder\nComputing persistent homology for Concord-class\n</pre> In\u00a0[48]: Copied! <pre>save_dir / f\"topology_diagrams_{file_suffix}.pkl\"\n</pre> save_dir / f\"topology_diagrams_{file_suffix}.pkl\" Out[48]: <pre>PosixPath('../save/dev_simulation_trajectory-Nov24/topology_diagrams_Nov24-2032.pkl')</pre> In\u00a0[6]: Copied! <pre>import pickle\nwith open(Path('../save/dev_simulation_trajectory-Nov24') / f\"topology_diagrams_Nov24-2032.pkl\", 'rb') as f:\n    diagrams = pickle.load(f)\n</pre> import pickle with open(Path('../save/dev_simulation_trajectory-Nov24') / f\"topology_diagrams_Nov24-2032.pkl\", 'rb') as f:     diagrams = pickle.load(f) In\u00a0[7]: Copied! <pre>topology_results = ccd.ul.benchmark_topology(diagrams, expected_betti_numbers=[0,0,0], save_dir=save_dir, file_suffix=file_suffix)\nmax_betti = 5\ntopology_metrics = topology_results['combined_metrics'].drop(index=['PCA_no_noise', 'PCA_wt_noise'])\ntopology_metrics[('Betti number', 'L1 distance')] = topology_metrics[('Betti number', 'L1 distance')].clip(upper=5)\nagg_name1 = 'Topology'\nagg_name2 = 'Score'\ntopology_scores = ccd.ul.benchmark_stats_to_score(topology_metrics, min_max_scale=True, one_minus=True, aggregate_score=True, aggregate_score_name1=agg_name1, aggregate_score_name2=agg_name2, rank=True, rank_col=(agg_name1,agg_name2), name_exact=False)\nccd.pl.plot_benchmark_table(topology_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', agg_name = agg_name1, save_path=save_dir / f\"topology_results_{file_suffix}.pdf\", figsize=(6, 6), dpi=300)\n</pre> topology_results = ccd.ul.benchmark_topology(diagrams, expected_betti_numbers=[0,0,0], save_dir=save_dir, file_suffix=file_suffix) max_betti = 5 topology_metrics = topology_results['combined_metrics'].drop(index=['PCA_no_noise', 'PCA_wt_noise']) topology_metrics[('Betti number', 'L1 distance')] = topology_metrics[('Betti number', 'L1 distance')].clip(upper=5) agg_name1 = 'Topology' agg_name2 = 'Score' topology_scores = ccd.ul.benchmark_stats_to_score(topology_metrics, min_max_scale=True, one_minus=True, aggregate_score=True, aggregate_score_name1=agg_name1, aggregate_score_name2=agg_name2, rank=True, rank_col=(agg_name1,agg_name2), name_exact=False) ccd.pl.plot_benchmark_table(topology_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', agg_name = agg_name1, save_path=save_dir / f\"topology_results_{file_suffix}.pdf\", figsize=(6, 6), dpi=300) In\u00a0[13]: Copied! <pre># Reorder diagrams with the same order as the combined keys\ndiagrams_ordered = {key: diagrams[key] for key in combined_keys}\n# Change the key names to remove 'PCA_'\ndiagrams_ordered = {key.replace('PCA_', ''): diagrams_ordered[key] for key in diagrams_ordered}\nccd.pl.plot_persistence_diagrams(diagrams_ordered, base_size=(1.3, 1.5), dpi=300, marker_size=4, n_cols=11, fontsize=10, save_path=save_dir / f\"persistence_diagrams_{file_suffix}.pdf\", legend=False, label_axes=False, axis_ticks=False)\n</pre> # Reorder diagrams with the same order as the combined keys diagrams_ordered = {key: diagrams[key] for key in combined_keys} # Change the key names to remove 'PCA_' diagrams_ordered = {key.replace('PCA_', ''): diagrams_ordered[key] for key in diagrams_ordered} ccd.pl.plot_persistence_diagrams(diagrams_ordered, base_size=(1.3, 1.5), dpi=300, marker_size=4, n_cols=11, fontsize=10, save_path=save_dir / f\"persistence_diagrams_{file_suffix}.pdf\", legend=False, label_axes=False, axis_ticks=False) In\u00a0[14]: Copied! <pre>ccd.pl.plot_betti_curves(diagrams_ordered, nbins=100, base_size=(1.3, 1.5), n_cols=11, fontsize=10, save_path=save_dir / f\"betti_curves_{file_suffix}.pdf\", dpi=300, legend=False, label_axes=False, axis_ticks=False)\n</pre> ccd.pl.plot_betti_curves(diagrams_ordered, nbins=100, base_size=(1.3, 1.5), n_cols=11, fontsize=10, save_path=save_dir / f\"betti_curves_{file_suffix}.pdf\", dpi=300, legend=False, label_axes=False, axis_ticks=False) In\u00a0[8]: Copied! <pre># compare connectivity for latent vs ground truth, store the result in a pandas dataframe\ngroundtruth_keys = {'(nn)': 'PCA_no_noise','(wn)': 'PCA_wt_noise'}\nconnectivity_df = ccd.ul.benchmark_graph_connectivity(adata, emb_keys=combined_keys, groundtruth_keys=groundtruth_keys, k=30)\nagg_name1 = 'Connectivity'\nagg_name2 = 'Score'\nconnectivity_scores = ccd.ul.benchmark_stats_to_score(connectivity_df, min_max_scale=False, one_minus=False, aggregate_score=True, aggregate_score_name1=agg_name1, aggregate_score_name2=agg_name2, rank=True, rank_col=(agg_name1,agg_name2), name_exact=False)\nccd.pl.plot_benchmark_table(connectivity_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', agg_name = agg_name1, save_path=save_dir / f\"connectivity_results_{file_suffix}.pdf\", figsize=(8, 8), dpi=300)\n</pre> # compare connectivity for latent vs ground truth, store the result in a pandas dataframe groundtruth_keys = {'(nn)': 'PCA_no_noise','(wn)': 'PCA_wt_noise'} connectivity_df = ccd.ul.benchmark_graph_connectivity(adata, emb_keys=combined_keys, groundtruth_keys=groundtruth_keys, k=30) agg_name1 = 'Connectivity' agg_name2 = 'Score' connectivity_scores = ccd.ul.benchmark_stats_to_score(connectivity_df, min_max_scale=False, one_minus=False, aggregate_score=True, aggregate_score_name1=agg_name1, aggregate_score_name2=agg_name2, rank=True, rank_col=(agg_name1,agg_name2), name_exact=False) ccd.pl.plot_benchmark_table(connectivity_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', agg_name = agg_name1, save_path=save_dir / f\"connectivity_results_{file_suffix}.pdf\", figsize=(8, 8), dpi=300)  <pre>Concord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\n</pre> In\u00a0[9]: Copied! <pre>latent_keys = [\"Unintegrated\", \"Scanorama\", \"Liger\", \"Harmony\", \"scVI\", \"scANVI\", \"Concord\", 'Concord-decoder', \"Concord-class\"]\nground_keys = ['PCA_no_noise', 'PCA_wt_noise']\ncombined_keys = ground_keys + latent_keys \n</pre> latent_keys = [\"Unintegrated\", \"Scanorama\", \"Liger\", \"Harmony\", \"scVI\", \"scANVI\", \"Concord\", 'Concord-decoder', \"Concord-class\"] ground_keys = ['PCA_no_noise', 'PCA_wt_noise'] combined_keys = ground_keys + latent_keys  In\u00a0[10]: Copied! <pre>geometry_metrics = ['pseudotime', 'cell_distance_corr', 'local_distal_corr', 'trustworthiness', 'state_distance_corr', 'state_dispersion_corr', 'state_batch_distance_ratio']\ndist_metric = 'cosine'\ncorr_types = ['pearsonr', 'spearmanr', 'kendalltau']\n#groundtruth_key = 'PCA_wt_noise'\ngroundtruth_key = 'PCA_no_noise'\n# Convert state_dispersion to a dict of groundtruth dispersion\n#groundtruth_dispersion = {'cluster_' + str(i): state_dispersion[i]**2 for i in range(5)} # convert to variance\ngeometry_df, geometry_full = ccd.ul.benchmark_geometry(adata, keys=combined_keys, eval_metrics=geometry_metrics, \n                                      dist_metric=dist_metric,\n                                      corr_types = corr_types,\n                                      groundtruth_key = groundtruth_key,\n                                      state_key = leiden_key,\n                                      batch_key = batch_key,\n                                      #groundtruth_dispersion = groundtruth_dispersion,\n                                      dispersion_metric='var',\n                                      return_type='full',\n                                      start_point=0,\n                                      end_point=adata.n_obs-1,\n                                      pseudotime_k = 30,\n                                      truetime_key = 'time',\n                                      save_dir=save_dir, \n                                      file_suffix=file_suffix)\n</pre> geometry_metrics = ['pseudotime', 'cell_distance_corr', 'local_distal_corr', 'trustworthiness', 'state_distance_corr', 'state_dispersion_corr', 'state_batch_distance_ratio'] dist_metric = 'cosine' corr_types = ['pearsonr', 'spearmanr', 'kendalltau'] #groundtruth_key = 'PCA_wt_noise' groundtruth_key = 'PCA_no_noise' # Convert state_dispersion to a dict of groundtruth dispersion #groundtruth_dispersion = {'cluster_' + str(i): state_dispersion[i]**2 for i in range(5)} # convert to variance geometry_df, geometry_full = ccd.ul.benchmark_geometry(adata, keys=combined_keys, eval_metrics=geometry_metrics,                                        dist_metric=dist_metric,                                       corr_types = corr_types,                                       groundtruth_key = groundtruth_key,                                       state_key = leiden_key,                                       batch_key = batch_key,                                       #groundtruth_dispersion = groundtruth_dispersion,                                       dispersion_metric='var',                                       return_type='full',                                       start_point=0,                                       end_point=adata.n_obs-1,                                       pseudotime_k = 30,                                       truetime_key = 'time',                                       save_dir=save_dir,                                        file_suffix=file_suffix) <pre>Concord - INFO - Computing pseudotime correlation\nConcord - INFO - Computing pseudotime for PCA_no_noise\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing pseudotime for PCA_wt_noise\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing pseudotime for Unintegrated\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Failed to compute shortest path for Unintegrated\nConcord - INFO - Computing pseudotime for Scanorama\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing pseudotime for Liger\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing pseudotime for Harmony\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing pseudotime for scVI\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing pseudotime for scANVI\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing pseudotime for Concord\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing pseudotime for Concord-decoder\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing pseudotime for Concord-class\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord - INFO - Finding path between point_0 and point_999\nConcord - INFO - Computing cell distance correlation\nConcord - INFO - Computing local vs distal correlation\nConcord - INFO - Computing trustworthiness\nConcord - INFO - Computing cluster centroid distances correlation\nConcord - INFO - Computing state dispersion correlation\nConcord - INFO - Computing state-batch distance ratio\n</pre> In\u00a0[11]: Copied! <pre>agg_name1 = 'Geometry'\nagg_name2 = 'Score'\ngeometry_scores = ccd.ul.benchmark_stats_to_score(\n    geometry_df.drop(index=['PCA_no_noise', 'PCA_wt_noise']), fillna = 0,               \n    min_max_scale=False, one_minus=False, aggregate_score=True, aggregate_score_name1=agg_name1, aggregate_score_name2=agg_name2, rank=True, rank_col=(agg_name1,agg_name2))\nccd.pl.plot_benchmark_table(geometry_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', agg_name = agg_name1, save_path=save_dir / f\"geometry_results_noscale_{dist_metric}_{groundtruth_key}_{file_suffix}.pdf\", figsize=(19, 7), dpi=300)\n</pre> agg_name1 = 'Geometry' agg_name2 = 'Score' geometry_scores = ccd.ul.benchmark_stats_to_score(     geometry_df.drop(index=['PCA_no_noise', 'PCA_wt_noise']), fillna = 0,                    min_max_scale=False, one_minus=False, aggregate_score=True, aggregate_score_name1=agg_name1, aggregate_score_name2=agg_name2, rank=True, rank_col=(agg_name1,agg_name2)) ccd.pl.plot_benchmark_table(geometry_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', agg_name = agg_name1, save_path=save_dir / f\"geometry_results_noscale_{dist_metric}_{groundtruth_key}_{file_suffix}.pdf\", figsize=(19, 7), dpi=300) In\u00a0[19]: Copied! <pre>pseudotime_result = geometry_full['Pseudotime']\npseudotime_result_no_noise = ccd.ul.compute_correlation(pseudotime_result['pseudotime'], corr_types=corr_types, groundtruth_key='PCA_no_noise')\npseudotime_result_wt_noise = ccd.ul.compute_correlation(pseudotime_result['pseudotime'], corr_types=corr_types, groundtruth_key='PCA_wt_noise')\npseudotime_result_no_noise\n</pre> pseudotime_result = geometry_full['Pseudotime'] pseudotime_result_no_noise = ccd.ul.compute_correlation(pseudotime_result['pseudotime'], corr_types=corr_types, groundtruth_key='PCA_no_noise') pseudotime_result_wt_noise = ccd.ul.compute_correlation(pseudotime_result['pseudotime'], corr_types=corr_types, groundtruth_key='PCA_wt_noise') pseudotime_result_no_noise Out[19]: pearsonr spearmanr kendalltau PCA_no_noise 1.000000 1.000000 1.000000 PCA_wt_noise 0.998643 0.998806 0.970763 Scanorama 0.997319 0.998587 0.967444 Liger 0.995380 0.996154 0.948276 Harmony 0.997182 0.998728 0.968596 scVI 0.997339 0.998775 0.971026 scANVI 0.998256 0.999170 0.975595 Concord 0.997259 0.999379 0.978573 Concord-decoder 0.998703 0.999245 0.977143 Concord-class 0.998540 0.999311 0.977275 time 0.999970 1.000000 0.999990 In\u00a0[29]: Copied! <pre>ccd.pl.plot_geometry_scatter(\n    data_dict = geometry_full['Pseudotime']['pseudotime'], \n    correlation= geometry_full['Pseudotime']['correlation'],\n    s=3,\n    ground_key = 'time', fontsize=9,\n    n_cols = 11, figsize=(1.7,2.1), dpi=300, save_path=save_dir / f\"pseudotime_scatter_{groundtruth_key}_{file_suffix}.pdf\")\n</pre> ccd.pl.plot_geometry_scatter(     data_dict = geometry_full['Pseudotime']['pseudotime'],      correlation= geometry_full['Pseudotime']['correlation'],     s=3,     ground_key = 'time', fontsize=9,     n_cols = 11, figsize=(1.7,2.1), dpi=300, save_path=save_dir / f\"pseudotime_scatter_{groundtruth_key}_{file_suffix}.pdf\") In\u00a0[12]: Copied! <pre>import matplotlib.pyplot as plt\n\nn_cols = 11\nn_rows = int(np.ceil(len(combined_keys) / n_cols))\nbase_size = (1.5, 1.7)\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*base_size[0], n_rows*base_size[1]), dpi=300)\n\naxes = np.atleast_2d(axes).flatten()\nfor basis in combined_keys:\n    show_basis = basis + '_UMAP'\n    if show_basis not in adata.obsm or basis not in geometry_full['Pseudotime']['pseudotime']:\n        show_indices = None\n        adata.obs['pseudotime_plot'] = np.nan\n    else:\n        show_indices = geometry_full['Pseudotime']['path'][basis]\n        adata.obs['pseudotime_plot'] = geometry_full['Pseudotime']['pseudotime'][basis]\n    \n    show_cols = ['pseudotime_plot']\n\n    ccd.pl.plot_embedding(\n        adata, show_basis, show_cols, highlight_indices=show_indices, highlight_size=5, draw_path=True, alpha=1.0,\n        font_size=12, point_size=10, path_width=1,\n        legend_loc='on data', title=basis, colorbar_loc=None, rasterized=True, xlabel=None, ylabel=None, \n        ax=axes[combined_keys.index(basis)]\n    )\n\nplt.tight_layout()\nplt.savefig(save_dir / f\"pseudotime_embedding_{file_suffix}.pdf\")\n</pre> import matplotlib.pyplot as plt  n_cols = 11 n_rows = int(np.ceil(len(combined_keys) / n_cols)) base_size = (1.5, 1.7) fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*base_size[0], n_rows*base_size[1]), dpi=300)  axes = np.atleast_2d(axes).flatten() for basis in combined_keys:     show_basis = basis + '_UMAP'     if show_basis not in adata.obsm or basis not in geometry_full['Pseudotime']['pseudotime']:         show_indices = None         adata.obs['pseudotime_plot'] = np.nan     else:         show_indices = geometry_full['Pseudotime']['path'][basis]         adata.obs['pseudotime_plot'] = geometry_full['Pseudotime']['pseudotime'][basis]          show_cols = ['pseudotime_plot']      ccd.pl.plot_embedding(         adata, show_basis, show_cols, highlight_indices=show_indices, highlight_size=5, draw_path=True, alpha=1.0,         font_size=12, point_size=10, path_width=1,         legend_loc='on data', title=basis, colorbar_loc=None, rasterized=True, xlabel=None, ylabel=None,          ax=axes[combined_keys.index(basis)]     )  plt.tight_layout() plt.savefig(save_dir / f\"pseudotime_embedding_{file_suffix}.pdf\") In\u00a0[26]: Copied! <pre>ccd.pl.plot_distance_heatmap(geometry_full['cell_distance_corr']['distance'], n_cols = 11, figsize=(1.1,1.3), cbar=False, dpi=300, save_path=save_dir / f\"cell_distance_hmap_{file_suffix}.pdf\")\n</pre> ccd.pl.plot_distance_heatmap(geometry_full['cell_distance_corr']['distance'], n_cols = 11, figsize=(1.1,1.3), cbar=False, dpi=300, save_path=save_dir / f\"cell_distance_hmap_{file_suffix}.pdf\") In\u00a0[137]: Copied! <pre>ccd.pl.plot_geometry_scatter(\n    data_dict = geometry_full['cell_distance_corr']['distance'], \n    correlation= geometry_full['cell_distance_corr']['correlation'],\n    s=0.1, alpha = 0.2,\n    n_cols = 3, figsize=(2,2), dpi=300, save_path=save_dir / f\"cell_distance_scatter_{file_suffix}.png\")\n</pre> ccd.pl.plot_geometry_scatter(     data_dict = geometry_full['cell_distance_corr']['distance'],      correlation= geometry_full['cell_distance_corr']['correlation'],     s=0.1, alpha = 0.2,     n_cols = 3, figsize=(2,2), dpi=300, save_path=save_dir / f\"cell_distance_scatter_{file_suffix}.png\") In\u00a0[30]: Copied! <pre>trustworthiness_scores = geometry_full['trustworthiness']['scores']\nccd.pl.plot_trustworthiness(trustworthiness_scores, text_shift=2, legend=True, save_path=save_dir / f\"trustworthiness_{groundtruth_key}_{file_suffix}.pdf\", figsize=(4,3))\n</pre> trustworthiness_scores = geometry_full['trustworthiness']['scores'] ccd.pl.plot_trustworthiness(trustworthiness_scores, text_shift=2, legend=True, save_path=save_dir / f\"trustworthiness_{groundtruth_key}_{file_suffix}.pdf\", figsize=(4,3)) In\u00a0[139]: Copied! <pre>ccd.pl.plot_distance_heatmap(geometry_full['state_distance_corr']['distance'], \n    n_cols = 3, annot_value=False,\n    figsize=(2,1.6), dpi=300, save_path=save_dir / f\"cell_distance_hmap_{file_suffix}.png\")\n</pre> ccd.pl.plot_distance_heatmap(geometry_full['state_distance_corr']['distance'],      n_cols = 3, annot_value=False,     figsize=(2,1.6), dpi=300, save_path=save_dir / f\"cell_distance_hmap_{file_suffix}.png\") In\u00a0[140]: Copied! <pre>ccd.pl.plot_geometry_scatter(\n    data_dict = geometry_full['state_distance_corr']['distance'], \n    correlation= geometry_full['state_distance_corr']['correlation'],\n    n_cols = 3, figsize=(2,2), dpi=300, save_path=save_dir / f\"state_distance_scatter_{file_suffix}.pdf\")\n</pre> ccd.pl.plot_geometry_scatter(     data_dict = geometry_full['state_distance_corr']['distance'],      correlation= geometry_full['state_distance_corr']['correlation'],     n_cols = 3, figsize=(2,2), dpi=300, save_path=save_dir / f\"state_distance_scatter_{file_suffix}.pdf\") In\u00a0[141]: Copied! <pre>ccd.pl.plot_geometry_scatter(\n    data_dict = geometry_full['state_dispersion_corr']['dispersion'], \n    correlation= geometry_full['state_dispersion_corr']['correlation'],\n    s=10,\n    ground_key = 'PCA_wt_noise',\n    n_cols = 3, figsize=(2,2), dpi=300, save_path=save_dir / f\"state_distance_scatter_{file_suffix}.pdf\")\n</pre> ccd.pl.plot_geometry_scatter(     data_dict = geometry_full['state_dispersion_corr']['dispersion'],      correlation= geometry_full['state_dispersion_corr']['correlation'],     s=10,     ground_key = 'PCA_wt_noise',     n_cols = 3, figsize=(2,2), dpi=300, save_path=save_dir / f\"state_distance_scatter_{file_suffix}.pdf\") In\u00a0[142]: Copied! <pre>plot_df = geometry_full['state_batch_distance_ratio'].drop(index=['PCA_no_noise', 'PCA_wt_noise'])\nccd.pl.plot_bar(plot_df, 'State-Batch Distance Ratio (log10)', save_path=save_dir / f\"state_batch_distance_ratio_{file_suffix}.pdf\", figsize=(3,2), dpi=300)\n</pre> plot_df = geometry_full['state_batch_distance_ratio'].drop(index=['PCA_no_noise', 'PCA_wt_noise']) ccd.pl.plot_bar(plot_df, 'State-Batch Distance Ratio (log10)', save_path=save_dir / f\"state_batch_distance_ratio_{file_suffix}.pdf\", figsize=(3,2), dpi=300) In\u00a0[143]: Copied! <pre>adata.layers\n</pre> adata.layers Out[143]: <pre>Layers with keys: wt_noise, counts, scVI_corrected_batch_1, Scanorama_corrected, Liger_corrected, scANVI_corrected_batch_1, Concord-decoder_decoded_batch_1, Concord-decoder_decoded_batch_2</pre> In\u00a0[144]: Copied! <pre># Align and copy the layer data based on observation names\nadata.layers['no_noise'] = np.zeros_like(adata.X)\n\n# Find the indices of common genes between `adata` and `adata_state`\ncommon_genes = adata.var_names.intersection(adata_state.var_names)\nadata_indices = adata.var_names.get_indexer(common_genes)\nadata_state_indices = adata_state.var_names.get_indexer(common_genes)\n\n# Copy data from `adata_state` to `adata` for these common genes\nadata.layers['no_noise'][:, adata_indices] = adata_state.layers['no_noise'][:, adata_state_indices].copy()\n\ndecoded_layers = ['Concord-decoder_decoded_batch_1', 'Concord-decoder_decoded_batch_2']\nshow_layers = ['no_noise', 'wt_noise'] + decoded_layers\nccd.pl.plot_adata_layer_heatmaps(adata, ncells=None, ngenes=None, layers=show_layers, cmap='viridis', vmin=0, vmax=7, \n                                 obs_keys=[state_key, batch_key], transpose=False, figsize=(6,6),  dpi=300, save_path=save_dir/f'decoded_heatmap_{file_suffix}.png')\n</pre> # Align and copy the layer data based on observation names adata.layers['no_noise'] = np.zeros_like(adata.X)  # Find the indices of common genes between `adata` and `adata_state` common_genes = adata.var_names.intersection(adata_state.var_names) adata_indices = adata.var_names.get_indexer(common_genes) adata_state_indices = adata_state.var_names.get_indexer(common_genes)  # Copy data from `adata_state` to `adata` for these common genes adata.layers['no_noise'][:, adata_indices] = adata_state.layers['no_noise'][:, adata_state_indices].copy()  decoded_layers = ['Concord-decoder_decoded_batch_1', 'Concord-decoder_decoded_batch_2'] show_layers = ['no_noise', 'wt_noise'] + decoded_layers ccd.pl.plot_adata_layer_heatmaps(adata, ncells=None, ngenes=None, layers=show_layers, cmap='viridis', vmin=0, vmax=7,                                   obs_keys=[state_key, batch_key], transpose=False, figsize=(6,6),  dpi=300, save_path=save_dir/f'decoded_heatmap_{file_suffix}.png') In\u00a0[145]: Copied! <pre># Compute the reconstruction error between the original and reconstructed data\nmse_no_noise = np.zeros(len(decoded_layers))\nmse_wt_noise = np.zeros(len(decoded_layers))\nstate_genes = adata.var_names[adata.var_names.isin(adata_state.var_names)]\nfor layer in decoded_layers:\n    mse_no_noise[decoded_layers.index(layer)] = ccd.ul.compute_reconstruction_error(adata[:,state_genes], 'no_noise', layer, metric='mse')\n    mse_wt_noise[decoded_layers.index(layer)] = ccd.ul.compute_reconstruction_error(adata[:,state_genes], 'wt_noise', layer, metric='mse')\n\n# Report value, mean\nprint(f\"MSE between no_noise and decoded layers: {mse_no_noise}\")\nprint(f\"MSE between wt_noise and decoded layers: {mse_wt_noise}\")\nprint(f\"Mean MSE between no_noise and decoded layers: {np.mean(mse_no_noise):.4f}\")\nprint(f\"Mean MSE between wt_noise and decoded layers: {np.mean(mse_wt_noise):.4f}\")\n</pre> # Compute the reconstruction error between the original and reconstructed data mse_no_noise = np.zeros(len(decoded_layers)) mse_wt_noise = np.zeros(len(decoded_layers)) state_genes = adata.var_names[adata.var_names.isin(adata_state.var_names)] for layer in decoded_layers:     mse_no_noise[decoded_layers.index(layer)] = ccd.ul.compute_reconstruction_error(adata[:,state_genes], 'no_noise', layer, metric='mse')     mse_wt_noise[decoded_layers.index(layer)] = ccd.ul.compute_reconstruction_error(adata[:,state_genes], 'wt_noise', layer, metric='mse')  # Report value, mean print(f\"MSE between no_noise and decoded layers: {mse_no_noise}\") print(f\"MSE between wt_noise and decoded layers: {mse_wt_noise}\") print(f\"Mean MSE between no_noise and decoded layers: {np.mean(mse_no_noise):.4f}\") print(f\"Mean MSE between wt_noise and decoded layers: {np.mean(mse_wt_noise):.4f}\")  <pre>MSE between no_noise and decoded layers: [0.35097491 0.32146425]\nMSE between wt_noise and decoded layers: [2.47886576 2.47109245]\nMean MSE between no_noise and decoded layers: 0.3362\nMean MSE between wt_noise and decoded layers: 2.4750\n</pre> In\u00a0[146]: Copied! <pre>basis = 'Concord'\npseudotime_k = 30\nstart_point = 0\nend_point = 100\nneighborhood = ccd.ml.Neighborhood(adata.obsm[basis], k=pseudotime_k, use_faiss=True)\npath, _ = ccd.ul.shortest_path_on_knn_graph(neighborhood, k=pseudotime_k, point_a=start_point, point_b=end_point, use_faiss=True)\n</pre> basis = 'Concord' pseudotime_k = 30 start_point = 0 end_point = 100 neighborhood = ccd.ml.Neighborhood(adata.obsm[basis], k=pseudotime_k, use_faiss=True) path, _ = ccd.ul.shortest_path_on_knn_graph(neighborhood, k=pseudotime_k, point_a=start_point, point_b=end_point, use_faiss=True)  <pre>Concord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_100\n</pre> In\u00a0[147]: Copied! <pre>show_cols = ['time']\nshow_indices = path\nshow_basis = basis + '_PCA'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, highlight_indices=show_indices, highlight_size=5, draw_path=True, alpha=1.0,\n    font_size=12, point_size=10, path_width=1,\n    legend_loc='on data', title=basis, colorbar_loc=None, rasterized=True, xlabel=None, ylabel=None,\n    figsize=(6, 6), dpi=300, save_path=save_dir / f\"pseudotime_embedding_{file_suffix}.pdf\"\n)\n</pre> show_cols = ['time'] show_indices = path show_basis = basis + '_PCA' ccd.pl.plot_embedding(     adata, show_basis, show_cols, highlight_indices=show_indices, highlight_size=5, draw_path=True, alpha=1.0,     font_size=12, point_size=10, path_width=1,     legend_loc='on data', title=basis, colorbar_loc=None, rasterized=True, xlabel=None, ylabel=None,     figsize=(6, 6), dpi=300, save_path=save_dir / f\"pseudotime_embedding_{file_suffix}.pdf\" ) In\u00a0[110]: Copied! <pre>adata.obsm['PCA_no_noise_PCA'] = adata_state.obsm['PCA_no_noise']\nadata.obsm['PCA_wt_noise_PCA'] = adata_state.obsm['PCA_wt_noise']\n</pre> adata.obsm['PCA_no_noise_PCA'] = adata_state.obsm['PCA_no_noise'] adata.obsm['PCA_wt_noise_PCA'] = adata_state.obsm['PCA_wt_noise'] In\u00a0[138]: Copied! <pre>curvature_res = {}\nfor basis in combined_keys:\n    print(f\"Computing curvature for {basis}\")\n    try:\n        curvature_res[basis]=ccd.ul.curvatures_across_time(adata, basis=basis, k=10, time_key='time', time_interval_frac=0.05)\n    except:\n        print(f\"Error computing curvature for {basis}\")\n        continue\n</pre> curvature_res = {} for basis in combined_keys:     print(f\"Computing curvature for {basis}\")     try:         curvature_res[basis]=ccd.ul.curvatures_across_time(adata, basis=basis, k=10, time_key='time', time_interval_frac=0.05)     except:         print(f\"Error computing curvature for {basis}\")         continue  <pre>Computing curvature for PCA_no_noise\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\nComputing curvature for PCA_wt_noise\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\nComputing curvature for Unintegrated\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nError computing curvature for Unintegrated\nComputing curvature for Scanorama\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\nComputing curvature for Liger\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\nComputing curvature for Harmony\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\nComputing curvature for scVI\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\nComputing curvature for scANVI\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\nComputing curvature for Concord\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\nComputing curvature for Concord-decoder\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\nComputing curvature for Concord-class\nConcord - INFO - Computing curvatures at time points: [  0.   49.9  99.8 149.7 199.6 249.5 299.4 349.3 399.2 449.1 499.  548.9\n 598.8 648.7 698.6 748.5 798.4 848.3 898.2 948.1]\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_24\nConcord - INFO - Finding path between point_24 and point_57\nConcord - INFO - Finding path between point_57 and point_570\nConcord - INFO - Finding path between point_570 and point_102\nConcord - INFO - Finding path between point_102 and point_127\nConcord - INFO - Finding path between point_127 and point_152\nConcord - INFO - Finding path between point_152 and point_667\nConcord - INFO - Finding path between point_667 and point_696\nConcord - INFO - Finding path between point_696 and point_235\nConcord - INFO - Finding path between point_235 and point_259\nConcord - INFO - Finding path between point_259 and point_292\nConcord - INFO - Finding path between point_292 and point_320\nConcord - INFO - Finding path between point_320 and point_342\nConcord - INFO - Finding path between point_342 and point_855\nConcord - INFO - Finding path between point_855 and point_388\nConcord - INFO - Finding path between point_388 and point_406\nConcord - INFO - Finding path between point_406 and point_926\nConcord - INFO - Finding path between point_926 and point_950\nConcord - INFO - Finding path between point_950 and point_478\nConcord - INFO - Finding path between point_478 and point_499\n</pre> In\u00a0[142]: Copied! <pre># Plot curvature as a function of time for each latent embedding in curvature_res, color by basis\nimport matplotlib.pyplot as plt\n\n\nfor basis in curvature_res:\n    vals = curvature_res[basis]['curvature']\n    curvature_res[basis]['curvature_minmax'] = (vals - vals.min()) / (vals.max() - vals.min())\n\n# Plot curvature as a function of time for each latent embedding in curvature_res, color by basis\nnrows = len(curvature_res)\nncols = 1\nbase_size=(6, 3)\nground_basis = 'PCA_no_noise'\n\nfig, ax = plt.subplots(nrows, ncols, figsize=(ncols*base_size[0], nrows*base_size[1]), dpi=300)\nfor i, basis in enumerate(curvature_res):\n    vals = curvature_res[basis]['curvature_minmax']\n    vals_ground = curvature_res[ground_basis]['curvature_minmax']\n    ax[i].plot(curvature_res[basis]['mid_time'], vals, label=basis)\n    ax[i].plot(curvature_res[ground_basis]['mid_time'], vals_ground, label=ground_basis)\n    ax[i].set_xlabel('Time')\n    ax[i].set_ylabel('Curvature')\n    ax[i].legend()\n\n\nplt.savefig(save_dir / f\"curvature_time_{file_suffix}.pdf\")\n</pre> # Plot curvature as a function of time for each latent embedding in curvature_res, color by basis import matplotlib.pyplot as plt   for basis in curvature_res:     vals = curvature_res[basis]['curvature']     curvature_res[basis]['curvature_minmax'] = (vals - vals.min()) / (vals.max() - vals.min())  # Plot curvature as a function of time for each latent embedding in curvature_res, color by basis nrows = len(curvature_res) ncols = 1 base_size=(6, 3) ground_basis = 'PCA_no_noise'  fig, ax = plt.subplots(nrows, ncols, figsize=(ncols*base_size[0], nrows*base_size[1]), dpi=300) for i, basis in enumerate(curvature_res):     vals = curvature_res[basis]['curvature_minmax']     vals_ground = curvature_res[ground_basis]['curvature_minmax']     ax[i].plot(curvature_res[basis]['mid_time'], vals, label=basis)     ax[i].plot(curvature_res[ground_basis]['mid_time'], vals_ground, label=ground_basis)     ax[i].set_xlabel('Time')     ax[i].set_ylabel('Curvature')     ax[i].legend()   plt.savefig(save_dir / f\"curvature_time_{file_suffix}.pdf\")   In\u00a0[143]: Copied! <pre># Compute correlation between curvature and groundtruth curvature\ncurvature_list = {\n    basis: curvature_res[basis]['curvature'] for basis in curvature_res\n}\ncorr_curvature = ccd.ul.compute_correlation(curvature_list, corr_types=corr_types, groundtruth_key=ground_basis)\ncorr_curvature\n    \n</pre> # Compute correlation between curvature and groundtruth curvature curvature_list = {     basis: curvature_res[basis]['curvature'] for basis in curvature_res } corr_curvature = ccd.ul.compute_correlation(curvature_list, corr_types=corr_types, groundtruth_key=ground_basis) corr_curvature      Out[143]: pearsonr spearmanr kendalltau PCA_no_noise 1.000000 1.000000 1.000000 PCA_wt_noise -0.529972 -0.477651 -0.337136 Scanorama -0.661655 -0.623979 -0.478515 Liger -0.162326 -0.097193 -0.093179 Harmony -0.485048 -0.527691 -0.380637 scVI -0.179533 -0.045491 -0.054377 scANVI -0.184196 -0.385154 -0.250133 Concord -0.039616 0.031843 0.043501 Concord-decoder -0.202897 -0.113726 -0.065252 Concord-class -0.087593 0.025020 0.043501 In\u00a0[126]: Copied! <pre>len(curvature_res[basis])\n</pre> len(curvature_res[basis]) Out[126]: <pre>10</pre> In\u00a0[144]: Copied! <pre>for basis in curvature_res:\n    # Initialize the column with NaN\n    adata.obs[f'curvature_{basis}'] = np.NaN\n\n    # Assign curvature values to cells between start and end points\n    for i in range(len(curvature_res[basis])):\n        # Extract scalar positional indices\n        start_point = int(curvature_res[basis]['start_point'].iloc[i])\n        end_point = int(curvature_res[basis]['end_point'].iloc[i])\n\n        # Assign curvature values using `.iloc` for position-based slicing\n        adata.obs.iloc[start_point:end_point + 1, adata.obs.columns.get_loc(f'curvature_{basis}')] = curvature_res[basis]['curvature'].iloc[i]\n</pre> for basis in curvature_res:     # Initialize the column with NaN     adata.obs[f'curvature_{basis}'] = np.NaN      # Assign curvature values to cells between start and end points     for i in range(len(curvature_res[basis])):         # Extract scalar positional indices         start_point = int(curvature_res[basis]['start_point'].iloc[i])         end_point = int(curvature_res[basis]['end_point'].iloc[i])          # Assign curvature values using `.iloc` for position-based slicing         adata.obs.iloc[start_point:end_point + 1, adata.obs.columns.get_loc(f'curvature_{basis}')] = curvature_res[basis]['curvature'].iloc[i]  In\u00a0[145]: Copied! <pre># Plot the curvature values on the UMAP embedding\nbasis = 'PCA_no_noise'\nshow_basis = f'{basis}_PCA'\nshow_cols = [f'curvature_{basis}']\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, highlight_indices=None, highlight_size=5, draw_path=False, alpha=1.0,\n    font_size=12, point_size=10, path_width=1,\n    legend_loc='on data', title='Curvature', colorbar_loc=None, rasterized=True, xlabel=None, ylabel=None,\n    figsize=(6, 6), dpi=300, save_path=save_dir / f\"curvature_embedding_{file_suffix}.pdf\"\n)\n</pre> # Plot the curvature values on the UMAP embedding basis = 'PCA_no_noise' show_basis = f'{basis}_PCA' show_cols = [f'curvature_{basis}'] ccd.pl.plot_embedding(     adata, show_basis, show_cols, highlight_indices=None, highlight_size=5, draw_path=False, alpha=1.0,     font_size=12, point_size=10, path_width=1,     legend_loc='on data', title='Curvature', colorbar_loc=None, rasterized=True, xlabel=None, ylabel=None,     figsize=(6, 6), dpi=300, save_path=save_dir / f\"curvature_embedding_{file_suffix}.pdf\" )  In\u00a0[153]: Copied! <pre>adata.obs[f'curvature_{basis}']\n</pre>  adata.obs[f'curvature_{basis}'] Out[153]: <pre>batch_1_Cell_1      1.432309\nbatch_1_Cell_3      1.432309\nbatch_1_Cell_4      1.432309\nbatch_1_Cell_6      1.432309\nbatch_1_Cell_7      1.432309\n                      ...   \nbatch_2_Cell_990         NaN\nbatch_2_Cell_991         NaN\nbatch_2_Cell_992         NaN\nbatch_2_Cell_996         NaN\nbatch_2_Cell_997         NaN\nName: curvature_Concord, Length: 1000, dtype: float64</pre> In\u00a0[178]: Copied! <pre>adata.obs[f'curvature_{basis}'].max()\n</pre> adata.obs[f'curvature_{basis}'].max() Out[178]: <pre>8.11891861960433</pre> In\u00a0[196]: Copied! <pre>#basis = 'PCA_no_noise'\nbasis = 'Concord'\nk=15\nneighborhood = ccd.ul.Neighborhood(adata.obsm[basis], k=k)\nshow_cols = ['time', f'curvature_{basis}']\nadata.obs[f'curvature_{basis}'] = np.nan\n#adata.obs[f'curvature_{basis}'] = np.linspace(0, 2, adata.n_obs)\nshow_basis = basis + '_PCA'\n\ninterval_frac = 0.06\ninterval = int(interval_frac * adata.n_obs)\nstep_frac = 0.02\nstep = int(step_frac * adata.n_obs)\ntime_vec = adata.obs['time']\ntime_points = np.arange(time_vec.min(), time_vec.max(), step)\n\nfor t in time_points:\n    # Extract scalar positional indices\n    start_time = i * step\n    end_time = start_time + interval\n    \n    start_point = np.argmin(np.abs(time_vec - t))\n    end_point = np.argmin(np.abs(time_vec - (t + interval)))\n\n    # Assign curvature values using `.iloc` for position-based slicing\n    path, _ = ccd.ul.shortest_path_on_knn_graph(neighborhood, point_a=start_point, point_b=end_point)\n    curvature = ccd.ul.curvature_along_path(adata, basis=basis, path=path)\n    curvature_new = pd.Series(curvature, index=path)\n    curvature_old = pd.Series(adata.obs.iloc[path, adata.obs.columns.get_loc(f'curvature_{basis}')], index=path)\n    #print(\"curvature_new\", curvature_new)\n    #print(\"curvature_old\", curvature_old)\n    curvature_df = pd.concat([curvature_old, curvature_new], axis=1)\n    # print(\"curvature_df\", curvature_df)\n    # print(\"curvature_df.mean(axis=1)\", curvature_df.mean(axis=1))\n    adata.obs.iloc[path, adata.obs.columns.get_loc(f'curvature_{basis}')] = curvature_df.mean(axis=1)\n    \n\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, highlight_indices=None, highlight_size=30, draw_path=False, alpha=1.0, ncols=2,\n    font_size=12, point_size=5, path_width=0.2,\n    legend_loc='on data', title=basis, colorbar_loc=None, rasterized=True, xlabel=None, ylabel=None,\n    figsize=(6, 3), dpi=300, save_path=None\n)\n</pre> #basis = 'PCA_no_noise' basis = 'Concord' k=15 neighborhood = ccd.ul.Neighborhood(adata.obsm[basis], k=k) show_cols = ['time', f'curvature_{basis}'] adata.obs[f'curvature_{basis}'] = np.nan #adata.obs[f'curvature_{basis}'] = np.linspace(0, 2, adata.n_obs) show_basis = basis + '_PCA'  interval_frac = 0.06 interval = int(interval_frac * adata.n_obs) step_frac = 0.02 step = int(step_frac * adata.n_obs) time_vec = adata.obs['time'] time_points = np.arange(time_vec.min(), time_vec.max(), step)  for t in time_points:     # Extract scalar positional indices     start_time = i * step     end_time = start_time + interval          start_point = np.argmin(np.abs(time_vec - t))     end_point = np.argmin(np.abs(time_vec - (t + interval)))      # Assign curvature values using `.iloc` for position-based slicing     path, _ = ccd.ul.shortest_path_on_knn_graph(neighborhood, point_a=start_point, point_b=end_point)     curvature = ccd.ul.curvature_along_path(adata, basis=basis, path=path)     curvature_new = pd.Series(curvature, index=path)     curvature_old = pd.Series(adata.obs.iloc[path, adata.obs.columns.get_loc(f'curvature_{basis}')], index=path)     #print(\"curvature_new\", curvature_new)     #print(\"curvature_old\", curvature_old)     curvature_df = pd.concat([curvature_old, curvature_new], axis=1)     # print(\"curvature_df\", curvature_df)     # print(\"curvature_df.mean(axis=1)\", curvature_df.mean(axis=1))     adata.obs.iloc[path, adata.obs.columns.get_loc(f'curvature_{basis}')] = curvature_df.mean(axis=1)       ccd.pl.plot_embedding(     adata, show_basis, show_cols, highlight_indices=None, highlight_size=30, draw_path=False, alpha=1.0, ncols=2,     font_size=12, point_size=5, path_width=0.2,     legend_loc='on data', title=basis, colorbar_loc=None, rasterized=True, xlabel=None, ylabel=None,     figsize=(6, 3), dpi=300, save_path=None ) <pre>Concord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss FlatL2 index.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - WARNING - K-NN graph is not computed. Computing now.\nConcord - INFO - Finding path between point_0 and point_30\nConcord - INFO - Finding path between point_509 and point_44\nConcord - INFO - Finding path between point_19 and point_57\nConcord - INFO - Finding path between point_30 and point_67\nConcord - INFO - Finding path between point_44 and point_76\nConcord - INFO - Finding path between point_57 and point_572\nConcord - INFO - Finding path between point_67 and point_580\nConcord - INFO - Finding path between point_76 and point_102\nConcord - INFO - Finding path between point_572 and point_112\nConcord - INFO - Finding path between point_580 and point_122\nConcord - INFO - Finding path between point_102 and point_131\nConcord - INFO - Finding path between point_112 and point_141\nConcord - INFO - Finding path between point_122 and point_153\nConcord - INFO - Finding path between point_131 and point_165\nConcord - INFO - Finding path between point_141 and point_177\nConcord - INFO - Finding path between point_153 and point_188\nConcord - INFO - Finding path between point_165 and point_199\nConcord - INFO - Finding path between point_177 and point_697\nConcord - INFO - Finding path between point_188 and point_216\nConcord - INFO - Finding path between point_199 and point_229\nConcord - INFO - Finding path between point_697 and point_728\nConcord - INFO - Finding path between point_216 and point_739\nConcord - INFO - Finding path between point_229 and point_260\nConcord - INFO - Finding path between point_728 and point_762\nConcord - INFO - Finding path between point_739 and point_284\nConcord - INFO - Finding path between point_260 and point_787\n</pre> <pre>Concord - INFO - Finding path between point_762 and point_304\nConcord - INFO - Finding path between point_284 and point_320\nConcord - INFO - Finding path between point_787 and point_818\nConcord - INFO - Finding path between point_304 and point_827\nConcord - INFO - Finding path between point_320 and point_348\nConcord - INFO - Finding path between point_818 and point_358\nConcord - INFO - Finding path between point_827 and point_855\nConcord - INFO - Finding path between point_348 and point_867\nConcord - INFO - Finding path between point_358 and point_385\nConcord - INFO - Finding path between point_855 and point_888\nConcord - INFO - Finding path between point_867 and point_399\nConcord - INFO - Finding path between point_385 and point_408\nConcord - INFO - Finding path between point_888 and point_415\nConcord - INFO - Finding path between point_399 and point_921\nConcord - INFO - Finding path between point_408 and point_932\nConcord - INFO - Finding path between point_415 and point_437\nConcord - INFO - Finding path between point_921 and point_449\nConcord - INFO - Finding path between point_932 and point_460\nConcord - INFO - Finding path between point_437 and point_973\nConcord - INFO - Finding path between point_449 and point_481\nConcord - INFO - Finding path between point_460 and point_989\nConcord - INFO - Finding path between point_973 and point_499\nConcord - INFO - Finding path between point_481 and point_499\nConcord - INFO - Finding path between point_989 and point_499\n</pre> In\u00a0[201]: Copied! <pre>ccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key, f'curvature_PCA_no_noise', f'curvature_{basis}'], \n                                cluster_cols=False, cluster_rows=False, cmap='viridis')\n\nccd.pl.heatmap_with_annotations(adata, val=basis+'_sorted', obs_keys=[state_key, batch_key, f'curvature_PCA_no_noise', f'curvature_{basis}'], \n                                cluster_cols=False, cluster_rows=False, cmap='viridis')\n</pre> ccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key, f'curvature_PCA_no_noise', f'curvature_{basis}'],                                  cluster_cols=False, cluster_rows=False, cmap='viridis')  ccd.pl.heatmap_with_annotations(adata, val=basis+'_sorted', obs_keys=[state_key, batch_key, f'curvature_PCA_no_noise', f'curvature_{basis}'],                                  cluster_cols=False, cluster_rows=False, cmap='viridis') Out[201]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f848c41a190&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/simulation_trajectory_full/#simulation-using-concord","title":"Simulation using Concord\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#no-batch-effect-no-noise","title":"No batch effect, no noise\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#no-batch-effect-noise-added-pca-and-umap","title":"NO batch effect, noise added, PCA and UMAP\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#no-batch-correction-pca-and-umap","title":"No batch correction, PCA and UMAP\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#concord","title":"Concord\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#run-other-methods","title":"Run other methods\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#scanorama","title":"Scanorama\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#liger","title":"Liger\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#harmony","title":"Harmony\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#scvi","title":"scVI\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#scanvi","title":"scANVI\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#concord","title":"Concord\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#concord-with-decoder","title":"Concord with decoder\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#concord-with-classifier","title":"Concord with classifier\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#concord-without-specifying-domain","title":"Concord without specifying domain\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#evaluation","title":"Evaluation\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#scib","title":"Scib\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#topology","title":"Topology\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#geomtric-features","title":"Geomtric Features\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#integrated-benchmark-pipeline","title":"Integrated benchmark pipeline\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#20-decoder-reconstruction","title":"2.0 Decoder reconstruction\u00b6","text":""},{"location":"notebooks/simulation_trajectory_full/#curvature-analysis","title":"Curvature analysis\u00b6","text":""}]}